{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fd4cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import statistics\n",
    "import scipy.stats\n",
    "import time\n",
    "\n",
    "from scipy.stats import norm, t\n",
    "from scipy.optimize import fsolve\n",
    "from skmultiflow.drift_detection.adwin import ADWIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bfd7e4",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d859f1",
   "metadata": {},
   "source": [
    "### Real-world datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b2661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "543b99a0",
   "metadata": {},
   "source": [
    "### Synthetic datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a7ed6",
   "metadata": {},
   "source": [
    "#### Incremental Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ae0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "incremental_drift = []\n",
    "dataset_size = 10000\n",
    "drift_probability = 0.0001\n",
    "drift_rate = 100\n",
    "mean = random.uniform(0, 1)\n",
    "means_incremental = [mean]\n",
    "drifts_incremental = [0]\n",
    "stdev = 1/6\n",
    "count = 0\n",
    "while(len(incremental_drift) < dataset_size):\n",
    "    if(random.uniform(0, 1) <= drift_probability):\n",
    "        new_mean = random.uniform(0, 1)\n",
    "        drifts_incremental.append(count)\n",
    "        means_incremental.append(new_mean)\n",
    "        for i in range(drift_rate):\n",
    "            random_drawn = -1\n",
    "            while(random_drawn < 0 or random_drawn > 1):\n",
    "                random_drawn = np.random.normal(((new_mean-mean)/(drift_rate-i))+mean,stdev)\n",
    "            incremental_drift.append(random_drawn)\n",
    "            count += 1\n",
    "        mean = new_mean\n",
    "    else:\n",
    "        random_drawn = np.random.normal(mean,stdev)\n",
    "        if random_drawn >= 0 and random_drawn <= 1:\n",
    "            incremental_drift.append(random_drawn)\n",
    "            count += 1\n",
    "\n",
    "incremental_drift = incremental_drift[:dataset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4297ca9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6356314020078591]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a1a86fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drifts_incremental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e957c",
   "metadata": {},
   "source": [
    "##### Sudden drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01de1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudden_drift = []\n",
    "dataset_size = 10000\n",
    "drift_probability = 0.0001\n",
    "mean = random.uniform(0, 1)\n",
    "means = [mean]\n",
    "drifts = [0]\n",
    "stdev = 1/32\n",
    "count = 0\n",
    "\n",
    "while(len(sudden_drift) < dataset_size):\n",
    "    if(random.uniform(0, 1) <= drift_probability):\n",
    "        mean = random.uniform(0, 1)\n",
    "        drifts.append(count)\n",
    "        means.append(mean)\n",
    "    \n",
    "    random_drawn = np.random.normal(mean,stdev)\n",
    "    if random_drawn >= 0 and random_drawn <= 1:\n",
    "        sudden_drift.append(random_drawn)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52657769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49052108186343657, 0.6805948210940868]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fda0112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5918]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd6099c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqQklEQVR4nO3df1jUZb7/8dcAAqYM+CMGKBSzPRmrZqkRapslK+aP7OQ55QnNWk+cCkqxcrHUUkvM0w8PRVqtibW0bp61Mi3LsLSS1PBYRmq16mrpoKYMgl9B4fP9o3WuJq1kGGYG7ufjuua6nPtzf2bed3cDL+7Pj7FZlmUJAADAYCGBLgAAACDQCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYLC3QBzUF9fb327dunqKgo2Wy2QJcDAADOgmVZOnr0qBISEhQS8strQASis7Bv3z4lJiYGugwAAOCFvXv36vzzz//FPgSisxAVFSXph/+gdrs9wNUAAICzUVlZqcTERPfv8V9CIDoLpw6T2e12AhEAAM3M2ZzuwknVAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOOFBboAoKVLyl3p9b675wzzYSUAgJ/DChEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QIaiNatW6cRI0YoISFBNptNr7/+usd2y7I0ffp0xcfHq3Xr1kpLS9PXX3/t0efw4cPKyMiQ3W5XTEyMxo8fr6qqKo8+n3/+ua688kpFRkYqMTFRc+fObeqhAQCAZiSggai6ulqXXHKJCgoKzrh97ty5ys/P14IFC7Rhwwa1adNG6enpOn78uLtPRkaGysrKtHr1aq1YsULr1q1TZmame3tlZaUGDx6szp07q7S0VP/93/+thx9+WM8//3yTjw8AADQPNsuyrEAXIUk2m02vvfaarr/+ekk/rA4lJCTo3nvv1X333SdJcrlccjgcKiws1OjRo7Vt2zYlJydr06ZN6tOnjyRp1apVGjp0qL799lslJCRo/vz5evDBB+V0OhUeHi5Jys3N1euvv67t27efVW2VlZWKjo6Wy+WS3W73/eDRoiXlrvR6391zhvmwEgAwS0N+fwftOUS7du2S0+lUWlqauy06OlopKSkqKSmRJJWUlCgmJsYdhiQpLS1NISEh2rBhg7vP7373O3cYkqT09HTt2LFDR44cOeN719TUqLKy0uMBAABarqANRE6nU5LkcDg82h0Oh3ub0+lUbGysx/awsDC1b9/eo8+ZXuPH7/FTeXl5io6Odj8SExMbPyAAABC0gjYQBdKUKVPkcrncj7179wa6JAAA0ISCNhDFxcVJksrLyz3ay8vL3dvi4uJ04MABj+0nT57U4cOHPfqc6TV+/B4/FRERIbvd7vEAAAAtV9AGoi5duiguLk7FxcXutsrKSm3YsEGpqamSpNTUVFVUVKi0tNTdZ82aNaqvr1dKSoq7z7p163TixAl3n9WrV+uiiy5Su3bt/DQaAAAQzAIaiKqqqrRlyxZt2bJF0g8nUm/ZskV79uyRzWbTxIkT9cgjj2j58uXaunWrbrnlFiUkJLivRLv44os1ZMgQ3X777dq4caM+/vhjZWdna/To0UpISJAk3XzzzQoPD9f48eNVVlamv/71r/qf//kfTZo0KUCjBgAAwSYskG/+6aef6uqrr3Y/PxVSxo0bp8LCQk2ePFnV1dXKzMxURUWFBgwYoFWrVikyMtK9T1FRkbKzszVo0CCFhIRo1KhRys/Pd2+Pjo7Wu+++q6ysLPXu3VsdO3bU9OnTPe5VBAAAzBY09yEKZtyHCI3BfYgAIDBaxH2IAAAA/CWgh8wA/DJWlwDAP1ghAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4fLkrcBYa8yWrAIDgxwoRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMF5QB6K6ujpNmzZNXbp0UevWrdW1a1fNmjVLlmW5+1iWpenTpys+Pl6tW7dWWlqavv76a4/XOXz4sDIyMmS32xUTE6Px48erqqrK38MBAABBKqgD0WOPPab58+frmWee0bZt2/TYY49p7ty5evrpp9195s6dq/z8fC1YsEAbNmxQmzZtlJ6eruPHj7v7ZGRkqKysTKtXr9aKFSu0bt06ZWZmBmJIAAAgCNmsHy+3BJnhw4fL4XBo4cKF7rZRo0apdevW+vOf/yzLspSQkKB7771X9913nyTJ5XLJ4XCosLBQo0eP1rZt25ScnKxNmzapT58+kqRVq1Zp6NCh+vbbb5WQkPCrdVRWVio6Oloul0t2u71pBouglpS7MtAlNNjuOcMCXQIABFRDfn8H9QpRv379VFxcrK+++kqS9Nlnn+mjjz7StddeK0natWuXnE6n0tLS3PtER0crJSVFJSUlkqSSkhLFxMS4w5AkpaWlKSQkRBs2bDjj+9bU1KiystLjAQAAWq6wQBfwS3Jzc1VZWalu3bopNDRUdXV1evTRR5WRkSFJcjqdkiSHw+Gxn8PhcG9zOp2KjY312B4WFqb27du7+/xUXl6eZsyY4evhAACAIBXUK0SvvvqqioqK9Morr2jz5s1avHixHn/8cS1evLhJ33fKlClyuVzux969e5v0/QAAQGAF9QrR/fffr9zcXI0ePVqS1KNHD/3jH/9QXl6exo0bp7i4OElSeXm54uPj3fuVl5erV69ekqS4uDgdOHDA43VPnjypw4cPu/f/qYiICEVERDTBiAAAQDAK6hWiY8eOKSTEs8TQ0FDV19dLkrp06aK4uDgVFxe7t1dWVmrDhg1KTU2VJKWmpqqiokKlpaXuPmvWrFF9fb1SUlL8MAoAABDsgnqFaMSIEXr00UfVqVMn/fa3v9X//d//6cknn9Qf/vAHSZLNZtPEiRP1yCOP6De/+Y26dOmiadOmKSEhQddff70k6eKLL9aQIUN0++23a8GCBTpx4oSys7M1evTos7rCDAAAtHxBHYiefvppTZs2TXfddZcOHDighIQE/dd//ZemT5/u7jN58mRVV1crMzNTFRUVGjBggFatWqXIyEh3n6KiImVnZ2vQoEEKCQnRqFGjlJ+fH4ghAQCAIBTU9yEKFtyHCNyHCACanxZzHyIAAAB/IBABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGC8s0AUAAMyRlLvS6313zxnmw0oAT6wQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHleZwRiNuboFANCysUIEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPGzMCLVRjbkS5e84wH1YC+Ab/T6MpsUIEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGM+rQLR37159++237ucbN27UxIkT9fzzz/usMAAAAH/xKhDdfPPNev/99yVJTqdTv//977Vx40Y9+OCDmjlzpk8LBAAAaGpeBaIvvvhCl19+uSTp1VdfVffu3bV+/XoVFRWpsLDQl/UBAAA0Oa8C0YkTJxQRESFJeu+993TddddJkrp166b9+/f7rjoAAAA/8CoQ/fa3v9WCBQv04YcfavXq1RoyZIgkad++ferQoYNPCwQAAGhqXgWixx57TM8995wGDhyo//iP/9All1wiSVq+fLn7UBoAAEBzEebNTgMHDtShQ4dUWVmpdu3audszMzN1zjnn+Kw4AAAAf/D6PkSWZam0tFTPPfecjh49KkkKDw8nEAEAgGbHq0D0j3/8Qz169NDIkSOVlZWlgwcPSvrhUNp9993n0wK/++47jRkzRh06dFDr1q3Vo0cPffrpp+7tlmVp+vTpio+PV+vWrZWWlqavv/7a4zUOHz6sjIwM2e12xcTEaPz48aqqqvJpnQAAoPnyKhBNmDBBffr00ZEjR9S6dWt3+7/+67+quLjYZ8UdOXJE/fv3V6tWrfT222/ryy+/1BNPPOFxmG7u3LnKz8/XggULtGHDBrVp00bp6ek6fvy4u09GRobKysq0evVqrVixQuvWrVNmZqbP6gQAAM2bV+cQffjhh1q/fr3Cw8M92pOSkvTdd9/5pDDphxWnxMRELVq0yN3WpUsX978ty9K8efM0depUjRw5UpL00ksvyeFw6PXXX9fo0aO1bds2rVq1Sps2bVKfPn0kSU8//bSGDh2qxx9/XAkJCT6rFwAANE9erRDV19errq7utPZvv/1WUVFRjS7qlOXLl6tPnz7693//d8XGxurSSy/VCy+84N6+a9cuOZ1OpaWluduio6OVkpKikpISSVJJSYliYmLcYUiS0tLSFBISog0bNpzxfWtqalRZWenxAAAALZdXK0SDBw/WvHnz3N9dZrPZVFVVpYceekhDhw71WXE7d+7U/PnzNWnSJD3wwAPatGmT7rnnHoWHh2vcuHFyOp2SJIfD4bGfw+Fwb3M6nYqNjfXYHhYWpvbt27v7/FReXp5mzJjhs3EAQEuSlLsy0CUAPufVCtETTzyhjz/+WMnJyTp+/Lhuvvlm9+Gyxx57zGfF1dfX67LLLtPs2bN16aWXKjMzU7fffrsWLFjgs/c4kylTpsjlcrkfe/fubdL3AwAAgeXVCtH555+vzz77TEuWLNHnn3+uqqoqjR8/XhkZGR4nWTdWfHy8kpOTPdouvvhi/e1vf5MkxcXFSZLKy8sVHx/v7lNeXq5evXq5+xw4cMDjNU6ePKnDhw+79/+piIgI91eTAACAls+rQCT9cNhpzJgxvqzlNP3799eOHTs82r766it17txZ0g8nWMfFxam4uNgdgCorK7VhwwbdeeedkqTU1FRVVFSotLRUvXv3liStWbNG9fX1SklJadL6AQBA83DWgWj58uVn/aKnvuy1sXJyctSvXz/Nnj1bN954ozZu3Kjnn3/e49yliRMn6pFHHtFvfvMbdenSRdOmTVNCQoKuv/56ST+sKA0ZMsR9qO3EiRPKzs7W6NGjucIMAABIakAgOhUwfo3NZjvjFWje6Nu3r1577TVNmTJFM2fOVJcuXTRv3jxlZGS4+0yePFnV1dXKzMxURUWFBgwYoFWrVikyMtLdp6ioSNnZ2Ro0aJBCQkI0atQo5efn+6RGAADQ/Nksy7ICXUSwq6ysVHR0tFwul+x2e6DLgZe4Mubs7Z4zLNAlIIiZ9lni89B8NeT3t9ffZQYAANBSeB2IiouLNXz4cHXt2lVdu3bV8OHD9d577/myNgAAAL/wKhA9++yzGjJkiKKiojRhwgRNmDBBdrtdQ4cOVUFBga9rBAAAaFJeXXY/e/ZsPfXUU8rOzna33XPPPerfv79mz56trKwsnxUIAADQ1LxaIaqoqNCQIUNOax88eLBcLlejiwIAAPAnrwLRddddp9dee+209jfeeEPDhw9vdFEAAAD+5NUhs+TkZD366KP64IMPlJqaKkn65JNP9PHHH+vee+/1uMfPPffc45tKAQAAmohXgWjhwoVq166dvvzyS3355Zfu9piYGC1cuND93GazEYgAAEDQ8yoQ7dq1y9d1AAAABAw3ZgQAAMbzaoXIsiz97//+r95//30dOHBA9fX1HtuXLVvmk+IAAAD8watANHHiRD333HO6+uqr5XA4ZLPZfF0XAACA33gViF5++WUtW7ZMQ4cO9XU9AAAAfufVOUTR0dG64IILfF0LAABAQHgViB5++GHNmDFD/+///T9f1wMAAOB3Xh0yu/HGG/WXv/xFsbGxSkpKUqtWrTy2b9682SfFAQAA+INXgWjcuHEqLS3VmDFjOKkaAAA0e14FopUrV+qdd97RgAEDfF0PAACA33l1DlFiYqLsdruvawEAAAgIrwLRE088ocmTJ2v37t0+LgcAAMD/vDpkNmbMGB07dkxdu3bVOeecc9pJ1YcPH/ZJcQAAAP7gVSCaN2+ej8sAAAAIHK+vMgMAAGgpvApEP3b8+HHV1tZ6tHHCNQAAaE68Oqm6urpa2dnZio2NVZs2bdSuXTuPBwAAQHPiVSCaPHmy1qxZo/nz5ysiIkJ/+tOfNGPGDCUkJOill17ydY0AAABNyqtDZm+++aZeeuklDRw4ULfddpuuvPJKXXjhhercubOKioqUkZHh6zoBAACajFcrRIcPH3Z/273dbndfZj9gwACtW7fOd9UBAAD4gVeB6IILLtCuXbskSd26ddOrr74q6YeVo5iYGJ8VBwAA4A9eBaLbbrtNn332mSQpNzdXBQUFioyMVE5Oju6//36fFggAANDUvDqHKCcnx/3vtLQ0bd++XaWlpbrwwgvVs2dPnxUHAADgDw1aISopKdGKFSs82k6dXH3HHXfomWeeUU1NjU8LBAAAaGoNCkQzZ85UWVmZ+/nWrVs1fvx4paWlacqUKXrzzTeVl5fn8yIBAACaUoMC0ZYtWzRo0CD38yVLliglJUUvvPCCcnJylJ+f7z7BGgAAoLloUCA6cuSIHA6H+/natWt17bXXup/37dtXe/fu9V11AAAAftCgQORwONyX29fW1mrz5s264oor3NuPHj2qVq1a+bZCAACAJtagQDR06FDl5ubqww8/1JQpU3TOOefoyiuvdG///PPP1bVrV58XCQAA0JQadNn9rFmzdMMNN+iqq65S27ZttXjxYoWHh7u3v/jiixo8eLDPiwQAAGhKDQpEHTt21Lp16+RyudS2bVuFhoZ6bF+6dKnatm3r0wIBAACamlc3ZoyOjj5je/v27RtVDAAAQCB49dUdAAAALQmBCAAAGI9ABAAAjOfVOURAoCTlrgx0CQCAFogVIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxuMqMwCnaczVfLvnDPNhJQDgH6wQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYr1kFojlz5shms2nixInutuPHjysrK0sdOnRQ27ZtNWrUKJWXl3vst2fPHg0bNkznnHOOYmNjdf/99+vkyZN+rh4AAASrZhOINm3apOeee049e/b0aM/JydGbb76ppUuXau3atdq3b59uuOEG9/a6ujoNGzZMtbW1Wr9+vRYvXqzCwkJNnz7d30MAAABBqlkEoqqqKmVkZOiFF15Qu3bt3O0ul0sLFy7Uk08+qWuuuUa9e/fWokWLtH79en3yySeSpHfffVdffvml/vznP6tXr1669tprNWvWLBUUFKi2tjZQQwIAAEGkWQSirKwsDRs2TGlpaR7tpaWlOnHihEd7t27d1KlTJ5WUlEiSSkpK1KNHDzkcDnef9PR0VVZWqqys7IzvV1NTo8rKSo8HAABouYL+qzuWLFmizZs3a9OmTadtczqdCg8PV0xMjEe7w+GQ0+l09/lxGDq1/dS2M8nLy9OMGTN8UD0ABKfGfD0L0BIF9QrR3r17NWHCBBUVFSkyMtJv7ztlyhS5XC73Y+/evX57bwAA4H9BHYhKS0t14MABXXbZZQoLC1NYWJjWrl2r/Px8hYWFyeFwqLa2VhUVFR77lZeXKy4uTpIUFxd32lVnp56f6vNTERERstvtHg8AANByBXUgGjRokLZu3aotW7a4H3369FFGRob7361atVJxcbF7nx07dmjPnj1KTU2VJKWmpmrr1q06cOCAu8/q1atlt9uVnJzs9zEBAIDgE9TnEEVFRal79+4ebW3atFGHDh3c7ePHj9ekSZPUvn172e123X333UpNTdUVV1whSRo8eLCSk5M1duxYzZ07V06nU1OnTlVWVpYiIiL8PiYAABB8gjoQnY2nnnpKISEhGjVqlGpqapSenq5nn33WvT00NFQrVqzQnXfeqdTUVLVp00bjxo3TzJkzA1g1AAAIJs0uEH3wwQcezyMjI1VQUKCCgoKf3adz58566623mrgyAADQXAX1OUQAAAD+QCACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPGa3Ze7AgDgT0m5K73ed/ecYT6sBE2JFSIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMF5YoAsAADRcUu7KQJcAtCgEIgAAmkhjguvuOcN8WAl+DYfMAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMx2X38DvunwIACDZBvUKUl5envn37KioqSrGxsbr++uu1Y8cOjz7Hjx9XVlaWOnTooLZt22rUqFEqLy/36LNnzx4NGzZM55xzjmJjY3X//ffr5MmT/hwKAAAIYkEdiNauXausrCx98sknWr16tU6cOKHBgwerurra3ScnJ0dvvvmmli5dqrVr12rfvn264YYb3Nvr6uo0bNgw1dbWav369Vq8eLEKCws1ffr0QAwJAAAEIZtlWVagizhbBw8eVGxsrNauXavf/e53crlcOvfcc/XKK6/o3/7t3yRJ27dv18UXX6ySkhJdccUVevvttzV8+HDt27dPDodDkrRgwQL98Y9/1MGDBxUeHn7a+9TU1Kimpsb9vLKyUomJiXK5XLLb7f4ZbAvGIbOWjbvr+gefo5aPz1LjVVZWKjo6+qx+fzerc4hcLpckqX379pKk0tJSnThxQmlpae4+3bp1U6dOndyBqKSkRD169HCHIUlKT0/XnXfeqbKyMl166aWnvU9eXp5mzJjRxKMBWia+qgBAcxTUh8x+rL6+XhMnTlT//v3VvXt3SZLT6VR4eLhiYmI8+jocDjmdTnefH4ehU9tPbTuTKVOmyOVyuR979+718WgAAEAwaTYrRFlZWfriiy/00UcfNfl7RUREKCIiosnfBwAABIdmsUKUnZ2tFStW6P3339f555/vbo+Li1Ntba0qKio8+peXlysuLs7d56dXnZ16fqoPAAAwW1AHIsuylJ2drddee01r1qxRly5dPLb37t1brVq1UnFxsbttx44d2rNnj1JTUyVJqamp2rp1qw4cOODus3r1atntdiUnJ/tnIAAAIKgF9SGzrKwsvfLKK3rjjTcUFRXlPucnOjparVu3VnR0tMaPH69Jkyapffv2stvtuvvuu5WamqorrrhCkjR48GAlJydr7Nixmjt3rpxOp6ZOnaqsrCwOiwEAAElBHojmz58vSRo4cKBH+6JFi3TrrbdKkp566imFhIRo1KhRqqmpUXp6up599ll339DQUK1YsUJ33nmnUlNT1aZNG40bN04zZ8701zAAAECQC+pAdDa3SIqMjFRBQYEKCgp+tk/nzp311ltv+bI0AADQggT1OUQAAAD+QCACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjhQW6AAAwVVLuykCXAOCfCETwCj/IAQAtCYEIAIAg1Jg/PHfPGebDSszAOUQAAMB4BCIAAGA8AhEAADAe5xABCBqcMwEgUFghAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8vu0eQIuQlLvS6313zxnmw0qAwOPz0HCsEAEAAOOxQmSwxvwFAQBAS8IKEQAAMB4rRADQCKy0Ai0DK0QAAMB4rBABMB6rPABYIQIAAMYzKhAVFBQoKSlJkZGRSklJ0caNGwNdEgAACALGHDL761//qkmTJmnBggVKSUnRvHnzlJ6erh07dig2NjbQ5QEAEBRMvamjzbIsK9BF+ENKSor69u2rZ555RpJUX1+vxMRE3X333crNzf3FfSsrKxUdHS2XyyW73e6Pcs8a5z4AAIJFsAWihvz+NmKFqLa2VqWlpZoyZYq7LSQkRGlpaSopKTmtf01NjWpqatzPXS6XpB/+wzaF7g+90ySvCwCAP3XKWer1vl/MSPdhJT849Xv7bNZ+jAhEhw4dUl1dnRwOh0e7w+HQ9u3bT+ufl5enGTNmnNaemJjYZDUCAGCy6HlN99pHjx5VdHT0L/YxIhA11JQpUzRp0iT38/r6eh0+fFgdOnSQzWYLYGW+VVlZqcTERO3duzfoDgXCE3PVPDBPzQdz1Xw0Zq4sy9LRo0eVkJDwq32NCEQdO3ZUaGioysvLPdrLy8sVFxd3Wv+IiAhFRER4tMXExDRliQFlt9v5gdBMMFfNA/PUfDBXzYe3c/VrK0OnGHHZfXh4uHr37q3i4mJ3W319vYqLi5WamhrAygAAQDAwYoVIkiZNmqRx48apT58+uvzyyzVv3jxVV1frtttuC3RpAAAgwIwJRDfddJMOHjyo6dOny+l0qlevXlq1atVpJ1qbJCIiQg899NBphwcRfJir5oF5aj6Yq+bDX3NlzH2IAAAAfo4R5xABAAD8EgIRAAAwHoEIAAAYj0AEAACMRyBq4QoKCpSUlKTIyEilpKRo48aNZ7XfkiVLZLPZdP311zdtgXBryFwVFhbKZrN5PCIjI/1Yrbka+pmqqKhQVlaW4uPjFRERoX/5l3/RW2+95adqzdaQuRo4cOBpnymbzaZhw4Lry0pbqoZ+rubNm6eLLrpIrVu3VmJionJycnT8+PHGFWGhxVqyZIkVHh5uvfjii1ZZWZl1++23WzExMVZ5efkv7rdr1y7rvPPOs6688kpr5MiR/inWcA2dq0WLFll2u93av3+/++F0Ov1ctXkaOk81NTVWnz59rKFDh1offfSRtWvXLuuDDz6wtmzZ4ufKzdPQufr+++89Pk9ffPGFFRoaai1atMi/hRuooXNVVFRkRUREWEVFRdauXbusd955x4qPj7dycnIaVQeBqAW7/PLLraysLPfzuro6KyEhwcrLy/vZfU6ePGn169fP+tOf/mSNGzeOQOQnDZ2rRYsWWdHR0X6qDqc0dJ7mz59vXXDBBVZtba2/SsQ/efPz78eeeuopKyoqyqqqqmqqEvFPDZ2rrKws65prrvFomzRpktW/f/9G1cEhsxaqtrZWpaWlSktLc7eFhIQoLS1NJSUlP7vfzJkzFRsbq/Hjx/ujTMj7uaqqqlLnzp2VmJiokSNHqqyszB/lGsubeVq+fLlSU1OVlZUlh8Oh7t27a/bs2aqrq/NX2Uby9jP1YwsXLtTo0aPVpk2bpioT8m6u+vXrp9LSUvdhtZ07d+qtt97S0KFDG1WLMXeqNs2hQ4dUV1d32p24HQ6Htm/ffsZ9PvroIy1cuFBbtmzxQ4U4xZu5uuiii/Tiiy+qZ8+ecrlcevzxx9WvXz+VlZXp/PPP90fZxvFmnnbu3Kk1a9YoIyNDb731lr755hvdddddOnHihB566CF/lG0kb+bqxzZu3KgvvvhCCxcubKoS8U/ezNXNN9+sQ4cOacCAAbIsSydPntQdd9yhBx54oFG1sEIESdLRo0c1duxYvfDCC+rYsWOgy8GvSE1N1S233KJevXrpqquu0rJly3TuuefqueeeC3Rp+JH6+nrFxsbq+eefV+/evXXTTTfpwQcf1IIFCwJdGn7BwoUL1aNHD11++eWBLgVn8MEHH2j27Nl69tlntXnzZi1btkwrV67UrFmzGvW6rBC1UB07dlRoaKjKy8s92svLyxUXF3da/7///e/avXu3RowY4W6rr6+XJIWFhWnHjh3q2rVr0xZtqIbO1Zm0atVKl156qb755pumKBHybp7i4+PVqlUrhYaGutsuvvhiOZ1O1dbWKjw8vElrNlVjPlPV1dVasmSJZs6c2ZQl4p+8matp06Zp7Nix+s///E9JUo8ePVRdXa3MzEw9+OCDCgnxbq2HFaIWKjw8XL1791ZxcbG7rb6+XsXFxUpNTT2tf7du3bR161Zt2bLF/bjuuut09dVXa8uWLUpMTPRn+UZp6FydSV1dnbZu3ar4+PimKtN43sxT//799c0337j/uJCkr776SvHx8YShJtSYz9TSpUtVU1OjMWPGNHWZkHdzdezYsdNCz6k/OqzGfD1ro07JRlBbsmSJFRERYRUWFlpffvmllZmZacXExLgvzx47dqyVm5v7s/tzlZn/NHSuZsyYYb3zzjvW3//+d6u0tNQaPXq0FRkZaZWVlQVqCEZo6Dzt2bPHioqKsrKzs60dO3ZYK1assGJjY61HHnkkUEMwhrc//wYMGGDddNNN/i7XaA2dq4ceesiKioqy/vKXv1g7d+603n33Xatr167WjTfe2Kg6OGTWgt100006ePCgpk+fLqfTqV69emnVqlXuk9f27Nnj9dIifKuhc3XkyBHdfvvtcjqdateunXr37q3169crOTk5UEMwQkPnKTExUe+8845ycnLUs2dPnXfeeZowYYL++Mc/BmoIxvDm59+OHTv00Ucf6d133w1EycZq6FxNnTpVNptNU6dO1Xfffadzzz1XI0aM0KOPPtqoOmyW1Zj1JQAAgOaP5QEAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEYAW4dZbb5XNZpPNZlOrVq3kcDj0+9//Xi+++KLHl6v+msLCQsXExDRdoQCCEoEIQIsxZMgQ7d+/X7t379bbb7+tq6++WhMmTNDw4cN18uTJQJcHIIgRiAC0GBEREYqLi9N5552nyy67TA888IDeeOMNvf322yosLJQkPfnkk+rRo4fatGmjxMRE3XXXXaqqqpIkffDBB7rtttvkcrncq00PP/ywJOnll19Wnz59FBUVpbi4ON188806cOBAgEYKwNcIRABatGuuuUaXXHKJli1bJkkKCQlRfn6+ysrKtHjxYq1Zs0aTJ0+WJPXr10/z5s2T3W7X/v37tX//ft13332SpBMnTmjWrFn67LPP9Prrr2v37t269dZbAzUsAD4WFugCAKCpdevWTZ9//rkkaeLEie72pKQkPfLII7rjjjv07LPPKjw8XNHR0bLZbIqLi/N4jT/84Q/uf19wwQXKz89X3759VVVVpbZt2/plHACaDitEAFo8y7Jks9kkSe+9954GDRqk8847T1FRURo7dqy+//57HTt27Bdfo7S0VCNGjFCnTp0UFRWlq666SpK0Z8+eJq8fQNMjEAFo8bZt26YuXbpo9+7dGj58uHr27Km//e1vKi0tVUFBgSSptrb2Z/evrq5Wenq67Ha7ioqKtGnTJr322mu/uh+A5oNDZgBatDVr1mjr1q3KyclRaWmp6uvr9cQTTygk5Ie/B1999VWP/uHh4aqrq/No2759u77//nvNmTNHiYmJkqRPP/3UPwMA4BesEAFoMWpqauR0OvXdd99p8+bNmj17tkaOHKnhw4frlltu0YUXXqgTJ07o6aef1s6dO/Xyyy9rwYIFHq+RlJSkqqoqFRcX69ChQzp27Jg6deqk8PBw937Lly/XrFmzAjRKAE2BQASgxVi1apXi4+OVlJSkIUOG6P3331d+fr7eeOMNhYaG6pJLLtGTTz6pxx57TN27d1dRUZHy8vI8XqNfv3664447dNNNN+ncc8/V3Llzde6556qwsFBLly5VcnKy5syZo8cffzxAowTQFGyWZVmBLgIAACCQWCECAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPH+P8qWzDj/TT+LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot truncated normal distribution  without drift\n",
    "plt.hist(sudden_drift, density=False, bins=30)  # density=False would make counts\n",
    "plt.ylabel('Samples')\n",
    "plt.xlabel('Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aef6ce",
   "metadata": {},
   "source": [
    "# ADWIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461d3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = incremental_drift\n",
    "dataset = sudden_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "013a2ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change detected in data: 6047 width: 672\n",
      "Change detected in data: 6079 width: 384\n",
      "Change detected in data: 6111 width: 352\n",
      "Change detected in data: 6207 width: 384\n",
      "Change detected in data: 6271 width: 384\n",
      "--- 0.1576087474822998 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Adwin implementation using skmultiflow\n",
    "delta = 0.001\n",
    "adwin = ADWIN(delta)\n",
    "drifts = []\n",
    "start_time = time.time()\n",
    "for i, x in zip(range(len(dataset)),dataset):\n",
    "    adwin.add_element(x)\n",
    "    if adwin.detected_change():\n",
    "        print('Change detected in data: ' + str(i), 'width:', adwin.width)\n",
    "        drifts.append(i)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afcb2dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6047, 6079, 6111, 6207, 6271]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca39a5",
   "metadata": {},
   "source": [
    "# OPTWIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cac19160-7ba8-494b-9cc8-04fe4d7e86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.base import DriftDetector\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t as t_stat\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'The iteration is not making good progress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "593c2ce6-64a4-42b5-9f51-df728361fc76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Optwin_river(DriftDetector):\n",
    "    #pre-compute optimal cut for all possible window sizes\n",
    "    def pre_compute_cuts(self, opt_cut, opt_phi):\n",
    "        if len(opt_cut) != 0 and len(opt_phi) != 0:\n",
    "            return opt_cut, opt_phi\n",
    "        self.W = []\n",
    "        for i in range(self.w_lenght_max+1):\n",
    "            if i < self.w_lenght_min:\n",
    "                opt_cut[i] = 0\n",
    "                opt_phi[i] = 0\n",
    "            else:\n",
    "                optimal_cut = fsolve(self.t_test, (len(self.W)-30)/len(self.W))\n",
    "                optimal_cut = math.floor(optimal_cut[0]*len(self.W)) #parse to integer\n",
    "                #phi_opt = scipy.stats.f.ppf(q=self.confidence_two_tailes, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
    "                phi_opt = scipy.stats.f.ppf(q=self.confidence, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
    "                opt_cut[i] = optimal_cut\n",
    "                opt_phi[i] = phi_opt\n",
    "            self.W.append(1)\n",
    "        self.W = []\n",
    "        return opt_cut, opt_phi\n",
    "    \n",
    "    def detect_outlier(self, x):\n",
    "        #add outliers back to historical window (they will make it harder to detect drifts from outliers in the new window)\n",
    "        while len(self.outliers_positions) > 0 and self.itt - self.outliers_positions[0] > len(self.W) - self.last_opt_cut:\n",
    "            value = self.outliers.pop(0)\n",
    "            position = self.outliers_positions.pop(0)\n",
    "            substitute = self.outliers_substitutes.pop(0)\n",
    "            self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, [substitute]) #remove substitute\n",
    "            self.stdev_h, self.summation_h, self.count_h, self.S_h = self.add_running_stdev(self.summation_h, self.count_h, self.S_h, [value]) #put back smallest outlier\n",
    "            self.W[self.last_opt_cut-1] = value\n",
    "        \n",
    "        historical_avg = self.summation_h / self.count_h\n",
    "        \n",
    "        #check if x is not an outlier\n",
    "        if x <= historical_avg + (self.stdev_h * self.outlier_threshold) and x >= historical_avg - (self.stdev_h * self.outlier_threshold):\n",
    "            return x\n",
    "        \n",
    "        #add x as outlier\n",
    "        self.outliers.append(x)\n",
    "        self.outliers_positions.append(self.itt)\n",
    "        self.outliers_substitutes.append(historical_avg)\n",
    "        \n",
    "        #pop smallest outlier from new_window if max_outliers is reached\n",
    "        if len(self.outliers) > self.max_outliers:\n",
    "            #check min outlier and its respective index\n",
    "            min_outlier_value = min(self.outliers, key=lambda x:abs(x-historical_avg))\n",
    "            min_outlier_idx = self.outliers.index(min_outlier_value)\n",
    "            \n",
    "            #add min outlier back to new_window\n",
    "            self.outliers.pop(min_outlier_idx)\n",
    "            position = self.outliers_positions.pop(min_outlier_idx)\n",
    "            position_in_W = len(self.W) - (self.itt - position)\n",
    "            substitute = self.outliers_substitutes.pop(min_outlier_idx)\n",
    "            self.stdev_new, self.summation_new, self.count_new, self.S_new = self.pop_from_running_stdev(self.summation_new, self.count_new, self.S_new, [substitute]) #remove substitute\n",
    "            self.stdev_new, self.summation_new, self.count_new, self.S_new = self.add_running_stdev(self.summation_new, self.count_new, self.S_new, [min_outlier_value]) #put back smallest outlier \n",
    "            self.W[position_in_W-1] = min_outlier_value\n",
    "        return historical_avg\n",
    "\n",
    "    \n",
    "    def insert_to_W(self, x):\n",
    "        if self.outlier_detection and len(self.W) > self.w_lenght_min:\n",
    "            x = self.detect_outlier(x)\n",
    "            \n",
    "        self.W.append(x)\n",
    "        \n",
    "        #add new value to running stdev\n",
    "        if self.running_average:\n",
    "            self.stdev_new, self.summation_new, self.count_new, self.S_new = self.add_running_stdev(self.summation_new, self.count_new, self.S_new, [x])\n",
    "        \n",
    "        #check if window is too large\n",
    "        if len(self.W) > self.w_lenght_max:\n",
    "            pop = self.W.pop(0)\n",
    "            #remove excedent value from running stdev\n",
    "            if self.running_average:\n",
    "                self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, [pop])\n",
    "                #walk with sliding window\n",
    "                self.stdev_new, self.summation_new, self.count_new, self.S_new = self.pop_from_running_stdev(self.summation_new, self.count_new, self.S_new, [self.W[self.last_opt_cut]])\n",
    "                self.stdev_h, self.summation_h, self.count_h, self.S_h = self.add_running_stdev(self.summation_h, self.count_h, self.S_h, [self.W[self.last_opt_cut]])\n",
    "        \n",
    "        self.itt += 1\n",
    "        return\n",
    "    \n",
    "    #https://stats.stackexchange.com/questions/24878/computation-of-new-standard-deviation-using-old-standard-deviation-after-change\n",
    "    def add_running_stdev(self, summation, count, S, x):\n",
    "        x_sum = sum(x)\n",
    "        if count >= 1:\n",
    "            oldMean = summation / count\n",
    "            summation += x_sum\n",
    "            count += len(x)\n",
    "            newMean = summation / count\n",
    "            for i in x:\n",
    "                S = S + (i-oldMean)*(i-newMean)\n",
    "                #            S = S + (x_sum-oldMean)*(x_sum-newMean)\n",
    "        else:\n",
    "            summation = x_sum\n",
    "            count = len(x)\n",
    "            if count <= 1:\n",
    "                S = 0\n",
    "            else:\n",
    "                newMean = summation / count\n",
    "                S = pow(scipy.stats.tstd(x),2)*(count-1)\n",
    "        #estimated Variance = (S / (k-1) )\n",
    "        #estimated Standard Deviation = sqrt(variance)\n",
    "        if (count > 1 and S > 0):\n",
    "            return math.sqrt(S / (count-1) ), summation, count, S\n",
    "        else:\n",
    "            return 0, summation, count, S\n",
    "        \n",
    "    def pop_from_running_stdev(self,summation, count, S, x):\n",
    "        if count > len(x):\n",
    "            oldMean = summation / count\n",
    "            x_sum = sum(x)\n",
    "            summation -= x_sum\n",
    "            count -= len(x)\n",
    "            newMean = summation / count\n",
    "            for i in x:\n",
    "                S = S - ((i-oldMean)*(i-newMean))\n",
    "        else:\n",
    "            summation = 0\n",
    "            count = 0 \n",
    "            S = 0\n",
    "        #estimated Variance = (S / (k-1) )\n",
    "        #estimated Standard Deviation = sqrt(variance)\n",
    "        if (count > 1 and S > 0):\n",
    "            return math.sqrt(S / (count-1) ), summation, count, S\n",
    "        else:\n",
    "            return 0, summation, count, S\n",
    "    \n",
    "    #add new element to window\n",
    "    def update(self, x):\n",
    "        x += 1\n",
    "        #add new element to window\n",
    "        self.iteration += 1\n",
    "        self.insert_to_W(x)\n",
    "        #check if window is too small\n",
    "        if len(self.W) < self.w_lenght_min:\n",
    "            self.drift_detected_last_it = False\n",
    "            self._drift_detected = False\n",
    "            self.in_warning_zone = True\n",
    "            self.sequence_drifts = 0\n",
    "            return False\n",
    "        \n",
    "        #check optimal window cut and phi\n",
    "        if self.pre_compute_optimal_cut:\n",
    "            #get pre-calculated optimal window cut and phi\n",
    "            optimal_cut = self.opt_cut[len(self.W)]\n",
    "            phi_opt = self.opt_phi[len(self.W)]\n",
    "        else:\n",
    "            #calculate optimal window cut and phi in real-time\n",
    "            if len(self.W) in self.opt_cut:\n",
    "                optimal_cut = self.opt_cut[len(self.W)]\n",
    "                phi_opt = self.opt_phi[len(self.W)]\n",
    "            else:\n",
    "                optimal_cut = fsolve(self.t_test, (len(self.W)-30)/len(self.W))\n",
    "                optimal_cut = math.floor(optimal_cut[0]*len(self.W)) #parse to integer\n",
    "                #phi_opt = scipy.stats.f.ppf(q=self.confidence_two_tailes, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
    "                phi_opt = scipy.stats.f.ppf(q=self.confidence, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
    "                self.opt_cut[len(self.W)] = optimal_cut\n",
    "                self.opt_phi[len(self.W)] = phi_opt\n",
    "                \n",
    "        \n",
    "        #update stdev and avg\n",
    "        if self.running_average:\n",
    "            #update running stdev and avg\n",
    "            if optimal_cut > self.last_opt_cut: #remove elements from window_new and add them to window_h\n",
    "                self.stdev_new, self.summation_new, self.count_new, self.S_new = self.pop_from_running_stdev(self.summation_new, self.count_new, self.S_new, self.W[self.last_opt_cut:optimal_cut])\n",
    "                self.stdev_h, self.summation_h, self.count_h, self.S_h = self.add_running_stdev(self.summation_h, self.count_h, self.S_h, self.W[self.last_opt_cut:optimal_cut])\n",
    "            elif optimal_cut < self.last_opt_cut: #remove elements from window_h and add them to window_new\n",
    "                self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, self.W[optimal_cut:self.last_opt_cut])\n",
    "                self.stdev_new, self.summation_new, self.count_new, self.S_new = self.add_running_stdev(self.summation_new, self.count_new, self.S_new, self.W[optimal_cut:self.last_opt_cut])\n",
    "            avg_h = self.summation_h / self.count_h\n",
    "            avg_new = self.summation_new / self.count_new\n",
    "            stdev_h = self.stdev_h\n",
    "            stdev_new = self.stdev_new\n",
    "            self.last_opt_cut = optimal_cut\n",
    "        else:\n",
    "            #recalculate stdev and avg\n",
    "            stdev_h = scipy.stats.tstd(self.W[:optimal_cut])\n",
    "            stdev_new = scipy.stats.tstd(self.W[optimal_cut:])\n",
    "            avg_h = sum(self.W[:optimal_cut]) / optimal_cut\n",
    "            avg_new = sum(self.W[optimal_cut:]) / (len(self.W[optimal_cut:]))\n",
    "            self.last_opt_cut = optimal_cut\n",
    "        \n",
    "        #add minimal noise to stdev\n",
    "        if stdev_h == 0 or stdev_new == 0:\n",
    "            stdev_h += self.minimum_noise\n",
    "            stdev_new += self.minimum_noise\n",
    "        \n",
    "        #check both sides of f and t-test (detexts drift and model that is still convergeding)\n",
    "        '''    \n",
    "        #f-test     \n",
    "        if max((stdev_new*stdev_new)/(stdev_h*stdev_h),(stdev_h*stdev_h)/(stdev_new*stdev_new)) > phi_opt:\n",
    "                return self.drift_reaction(\"f\")\n",
    "    \n",
    "        #t-test\n",
    "        if max(avg_h-avg_new,avg_new-avg_h) > self.rigor * stdev_h:\n",
    "            return self.drift_reaction(\"t\")\n",
    "\n",
    "        '''\n",
    "        \n",
    "        #check only one side of f and t-test (if the loss decreases it means that the model is learning, not that a concept drift occurred\n",
    "        #f-test\n",
    "        if (stdev_new*stdev_new)/(stdev_h*stdev_h) > phi_opt:\n",
    "                return self.drift_reaction(\"f\")\n",
    "    \n",
    "        #t-test\n",
    "        if avg_new-avg_h > self.rigor * stdev_h:\n",
    "            return self.drift_reaction(\"t\")\n",
    "\n",
    "        \n",
    "        self.drift_detected_last_it = False\n",
    "        self._drift_detected = False\n",
    "        self.in_warning_zone = False\n",
    "        self.sequence_drifts = 0\n",
    "        self.sequence_no_drifts += 1\n",
    "        return self\n",
    "    \n",
    "    def drift_reaction(self, drift_type):\n",
    "        #print(self.itt)\n",
    "        self.sequence_drifts += 1\n",
    "        self.sequence_no_drifts = 0\n",
    "        #if self.sequence_drifts < 1:\n",
    "        #    return False\n",
    "            \n",
    "        self.drift_type.append(drift_type)\n",
    "        self.drifts.append(self.iteration)\n",
    "        if self.fixed_window_size == -1:\n",
    "            if self.empty_w:\n",
    "                self.empty_window()\n",
    "            else:\n",
    "                if self.running_average:\n",
    "                    self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, self.W[:optimal_cut])\n",
    "                self.W = self.W[optimal_cut:]\n",
    "                \n",
    "        self.drift_detected_last_it = True\n",
    "        self.in_warning_zone = True\n",
    "        self._drift_detected = True\n",
    "        self.outliers = []\n",
    "        self.outliers_substitutes = []\n",
    "        self.outliers_positions = []\n",
    "        return True\n",
    "        \n",
    "    def reset(self):\n",
    "        self.empty_window()\n",
    "        self.drifts = []\n",
    "        self.drift_type = []\n",
    "        self.itt = 0\n",
    "        self._reset()\n",
    "    \n",
    "    def empty_window(self):\n",
    "        self.W = []\n",
    "        self.sequence_drifts = 0\n",
    "        if self.running_average:\n",
    "            self.stdev_new = 0\n",
    "            self.summation_new = 0\n",
    "            self.count_new = 0\n",
    "            self.S_new = 0\n",
    "            self.stdev_h = 0\n",
    "            self.summation_h = 0\n",
    "            self.count_h = 0\n",
    "            self.S_h = 0\n",
    "            self.last_opt_cut = 0\n",
    "        self.outliers = []\n",
    "        self.outliers_substitutes = []\n",
    "        self.outliers_positions = []\n",
    "            \n",
    "    def detected_change(self):\n",
    "        return self.drift_detected_last_it\n",
    "    \n",
    "    def get_length_estimation(self):\n",
    "        self.estimation = len(self.W)\n",
    "        return len(self.W)\n",
    "    \n",
    "    def detected_warning_zone(self):\n",
    "        if self.sequence_drifts > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __init__(self, confidence_final = 0.999, rigor = 0.3, fixed_window_size = -1, empty_w=True, w_lenght_max = 10000, w_lenght_min = 60, minimum_noise = 1e-15, opt_cut = {}, opt_phi = {}, max_outliers = 5, outlier_threshold = 3, pre_compute_optimal_cut = True, running_average = True, outlier_detection= True):\n",
    "        #init variables\n",
    "        super().__init__()\n",
    "        self.confidence_final = confidence_final #confidence value chosen by user\n",
    "        self.rigor = rigor #rigorousness of drift identification\n",
    "        self.w_lenght_max = w_lenght_max #maximum window size\n",
    "        self.w_lenght_min = w_lenght_min #minimum window size\n",
    "        self.minimum_noise = minimum_noise #noise to be added to stdev in case it is 0\n",
    "        self.fixed_window_size = fixed_window_size #minimum window size\n",
    "        self.pre_compute_optimal_cut = pre_compute_optimal_cut #pre_compute all possible window sizes?\n",
    "        self.running_average = running_average #calculate stdev and avg with running sliding window?\n",
    "        self.empty_w = empty_w #empty window when drift is detected\n",
    "        \n",
    "        \n",
    "        self.W = [] #window\n",
    "        self.opt_cut = opt_cut #pre-calculated optimal cut for all possible windows\n",
    "        self.opt_phi = opt_phi #pre-calculated optimal phi for all possible windows\n",
    "        self.last_opt_cut = 0\n",
    "        self.drifts = [] #drifts identified \n",
    "        self.drift_type = [] #types of drifts identified\n",
    "        self.iteration = 0 #current iteration step\n",
    "        self.confidence = pow(self.confidence_final, 1/2) #confidence used on the t-test\n",
    "        #self.confidence_two_tailes = 1-(1-self.confidence)/2 #confidence used on the f-test\n",
    "        self.t_score = lambda w_lenght : t_stat.ppf(self.confidence, df=w_lenght-2) #t_value to achieve desired confidence\n",
    "        #self.f_test = lambda n : scipy.stats.f.ppf(q=self.confidence_two_tailes, dfn=(n*len(self.W))-1, dfd=len(self.W)-(n*len(self.W))-1) #f-test formula\n",
    "        self.f_test = lambda n : scipy.stats.f.ppf(q=self.confidence, dfn=(n*len(self.W))-1, dfd=len(self.W)-(n*len(self.W))-1) #f-test formula\n",
    "        self.t_test = lambda n : self.rigor - (self.t_score(len(self.W)) * np.sqrt((1/(len(self.W)*n))+((1* self.f_test(n))/((1-n)*len(self.W))))) #t-test formula (stdev_h=1 because it is cancelled during solution)\n",
    "    \n",
    "        #Running stdev and avg\n",
    "        self.stdev_new = 0\n",
    "        self.summation_new = 0\n",
    "        self.count_new = 0\n",
    "        self.S_new = 0\n",
    "        self.stdev_h = 0\n",
    "        self.summation_h = 0\n",
    "        self.count_h = 0\n",
    "        self.S_h = 0\n",
    "        \n",
    "        #Current outliers\n",
    "        self.max_outliers = max_outliers\n",
    "        self.biggest_non_outlier = 0\n",
    "        self.outliers = []\n",
    "        self.outliers_substitutes = []\n",
    "        self.outliers_positions = []\n",
    "        self.outlier_threshold = outlier_threshold\n",
    "        self.outlier_detection = outlier_detection\n",
    "        \n",
    "        self.itt = 0\n",
    "    \n",
    "        self.drift_detected_last_it = False\n",
    "        self.in_concept_change = False\n",
    "        self.in_warning_zone = False\n",
    "        self.estimation = 0.0\n",
    "        self.delay = 0.0\n",
    "        self.sequence_drifts = 0\n",
    "        self.sequence_no_drifts = 0\n",
    "        \n",
    "    \n",
    "        if self.fixed_window_size != -1:\n",
    "            self.w_lenght_max = self.fixed_window_size\n",
    "            self.w_lenght_min = self.fixed_window_size   \n",
    "            self.pre_compute_optimal_cut = False\n",
    "    \n",
    "        #pre-compute optimal cut for all possible window sizes (if True)\n",
    "        if self.pre_compute_optimal_cut:\n",
    "            self.opt_cut, self.opt_phi = self.pre_compute_cuts(self.opt_cut, self.opt_phi)\n",
    "            \n",
    "        if len(self.opt_cut) >= w_lenght_max and len(self.opt_phi) >= w_lenght_max:\n",
    "            self.pre_compute_optimal_cut = True\n",
    "\n",
    "        #super().reset()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05cf8629-3544-45db-b804-418f002a9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "max_samples = len(dataset) #max size of the dataset\n",
    "w_lenght_min=60 # > 30\n",
    "rigor = 0.05\n",
    "error = 1e-8\n",
    "confidence_final = 1-error\n",
    "minimum_noise=1e-15\n",
    "outlier_detection=False\n",
    "max_outliers=10\n",
    "outlier_threshold=3\n",
    "\n",
    "opt = Optwin_river(minimum_noise=minimum_noise, outlier_detection=outlier_detection, max_outliers=max_outliers, outlier_threshold = outlier_threshold, pre_compute_optimal_cut = False, w_lenght_max=max_samples+1, w_lenght_min=w_lenght_min, rigor = rigor, confidence_final=confidence_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bc9da04-691e-41e3-8a16-b3ac653d2dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "119\n",
      "181\n",
      "280\n",
      "413\n",
      "475\n",
      "577\n",
      "640\n",
      "700\n",
      "1444\n",
      "1504\n",
      "1564\n",
      "1624\n",
      "1684\n",
      "1746\n",
      "1806\n",
      "1866\n",
      "1926\n",
      "1986\n",
      "2046\n",
      "2108\n",
      "2273\n",
      "2333\n",
      "2401\n",
      "2461\n",
      "2521\n",
      "2581\n",
      "2647\n",
      "2795\n",
      "3742\n",
      "3803\n",
      "3865\n",
      "3982\n",
      "4042\n",
      "4102\n",
      "4162\n",
      "4222\n",
      "4283\n",
      "4671\n",
      "4731\n",
      "4792\n",
      "4856\n",
      "4993\n",
      "5055\n",
      "5115\n",
      "5175\n",
      "5237\n",
      "5299\n",
      "5360\n",
      "5424\n",
      "5486\n",
      "5554\n",
      "5729\n",
      "5924\n",
      "5984\n",
      "6101\n",
      "6161\n",
      "6223\n",
      "6283\n",
      "6456\n",
      "6516\n",
      "6597\n",
      "6657\n",
      "6717\n",
      "6779\n",
      "6841\n",
      "6903\n",
      "7035\n",
      "7095\n",
      "7155\n",
      "7215\n",
      "7275\n",
      "7336\n",
      "7397\n",
      "7990\n",
      "8197\n",
      "8257\n",
      "8410\n",
      "8478\n",
      "8590\n",
      "8650\n",
      "8710\n",
      "8810\n",
      "8932\n",
      "9107\n",
      "9168\n",
      "9228\n",
      "9288\n",
      "9348\n",
      "9506\n",
      "9566\n",
      "9626\n",
      "9705\n",
      "9864\n",
      "9925\n",
      "9985\n",
      "--- 0.03921198844909668 seconds ---\n"
     ]
    }
   ],
   "source": [
    "opt.reset()\n",
    "dataset = sudden_drift\n",
    "start_time = time.time()\n",
    "for i, d in zip(range(len(dataset)), dataset):\n",
    "    opt.update(d)\n",
    "    if opt.drift_detected:\n",
    "        print(i)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4946df9f-03bf-470b-8ce5-277d4712fca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2458fc89-ceae-4326-939f-b99db97c97ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.012454 s\n",
       "File: /var/folders/2n/q6cp8p7n06z0_2l_1b_m6sh4_pwsks/T/ipykernel_1121/3983661899.py\n",
       "Function: update at line 130\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   130                                               def update(self, x):\n",
       "   131         1          3.0      3.0      0.0          x += 1\n",
       "   132                                                   #add new element to window\n",
       "   133         1          3.0      3.0      0.0          self.iteration += 1\n",
       "   134         1         20.0     20.0      0.2          self.insert_to_W(x)\n",
       "   135                                                   #check if window is too small\n",
       "   136         1          2.0      2.0      0.0          if len(self.W) < self.w_lenght_min:\n",
       "   137                                                       self.drift_detected_last_it = False\n",
       "   138                                                       self._drift_detected = False\n",
       "   139                                                       self.in_warning_zone = True\n",
       "   140                                                       self.sequence_drifts = 0\n",
       "   141                                                       return False\n",
       "   142                                                   \n",
       "   143                                                   #check optimal window cut and phi\n",
       "   144         1          1.0      1.0      0.0          if self.pre_compute_optimal_cut:\n",
       "   145                                                       #get pre-calculated optimal window cut and phi\n",
       "   146                                                       optimal_cut = self.opt_cut[len(self.W)]\n",
       "   147                                                       phi_opt = self.opt_phi[len(self.W)]\n",
       "   148                                                   else:\n",
       "   149                                                       #calculate optimal window cut and phi in real-time\n",
       "   150         1          2.0      2.0      0.0              if len(self.W) in self.opt_cut:\n",
       "   151                                                           optimal_cut = self.opt_cut[len(self.W)]\n",
       "   152                                                           phi_opt = self.opt_phi[len(self.W)]\n",
       "   153                                                       else:\n",
       "   154         1      12028.0  12028.0     96.6                  optimal_cut = fsolve(self.t_test, (len(self.W)-30)/len(self.W))\n",
       "   155         1          8.0      8.0      0.1                  optimal_cut = math.floor(optimal_cut[0]*len(self.W)) #parse to integer\n",
       "   156                                                           #phi_opt = scipy.stats.f.ppf(q=self.confidence_two_tailes, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
       "   157         1        332.0    332.0      2.7                  phi_opt = scipy.stats.f.ppf(q=self.confidence, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
       "   158         1          3.0      3.0      0.0                  self.opt_cut[len(self.W)] = optimal_cut\n",
       "   159         1          2.0      2.0      0.0                  self.opt_phi[len(self.W)] = phi_opt\n",
       "   160                                                           \n",
       "   161                                                   \n",
       "   162                                                   #update stdev and avg\n",
       "   163         1          2.0      2.0      0.0          if self.running_average:\n",
       "   164                                                       #update running stdev and avg\n",
       "   165         1          2.0      2.0      0.0              if optimal_cut > self.last_opt_cut: #remove elements from window_new and add them to window_h\n",
       "   166         1         12.0     12.0      0.1                  self.stdev_new, self.summation_new, self.count_new, self.S_new = self.pop_from_running_stdev(self.summation_new, self.count_new, self.S_new, self.W[self.last_opt_cut:optimal_cut])\n",
       "   167         1         13.0     13.0      0.1                  self.stdev_h, self.summation_h, self.count_h, self.S_h = self.add_running_stdev(self.summation_h, self.count_h, self.S_h, self.W[self.last_opt_cut:optimal_cut])\n",
       "   168                                                       elif optimal_cut < self.last_opt_cut: #remove elements from window_h and add them to window_new\n",
       "   169                                                           self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, self.W[optimal_cut:self.last_opt_cut])\n",
       "   170                                                           self.stdev_new, self.summation_new, self.count_new, self.S_new = self.add_running_stdev(self.summation_new, self.count_new, self.S_new, self.W[optimal_cut:self.last_opt_cut])\n",
       "   171         1          2.0      2.0      0.0              avg_h = self.summation_h / self.count_h\n",
       "   172         1          2.0      2.0      0.0              avg_new = self.summation_new / self.count_new\n",
       "   173         1          1.0      1.0      0.0              stdev_h = self.stdev_h\n",
       "   174         1          1.0      1.0      0.0              stdev_new = self.stdev_new\n",
       "   175         1          1.0      1.0      0.0              self.last_opt_cut = optimal_cut\n",
       "   176                                                   else:\n",
       "   177                                                       #recalculate stdev and avg\n",
       "   178                                                       stdev_h = scipy.stats.tstd(self.W[:optimal_cut])\n",
       "   179                                                       stdev_new = scipy.stats.tstd(self.W[optimal_cut:])\n",
       "   180                                                       avg_h = sum(self.W[:optimal_cut]) / optimal_cut\n",
       "   181                                                       avg_new = sum(self.W[optimal_cut:]) / (len(self.W[optimal_cut:]))\n",
       "   182                                                       self.last_opt_cut = optimal_cut\n",
       "   183                                                   \n",
       "   184                                                   #add minimal noise to stdev\n",
       "   185         1          1.0      1.0      0.0          if stdev_h == 0 or stdev_new == 0:\n",
       "   186                                                       stdev_h += self.minimum_noise\n",
       "   187                                                       stdev_new += self.minimum_noise\n",
       "   188                                                   \n",
       "   189                                                   #check both sides of f and t-test (detexts drift and model that is still convergeding)\n",
       "   190                                                   '''    \n",
       "   191                                                   #f-test     \n",
       "   192                                                   if max((stdev_new*stdev_new)/(stdev_h*stdev_h),(stdev_h*stdev_h)/(stdev_new*stdev_new)) > phi_opt:\n",
       "   193                                                           return self.drift_reaction(\"f\")\n",
       "   194                                               \n",
       "   195                                                   #t-test\n",
       "   196                                                   if max(avg_h-avg_new,avg_new-avg_h) > self.rigor * stdev_h:\n",
       "   197                                                       return self.drift_reaction(\"t\")\n",
       "   198                                           \n",
       "   199                                                   '''\n",
       "   200                                                   \n",
       "   201                                                   #check only one side of f and t-test (if the loss decreases it means that the model is learning, not that a concept drift occurred\n",
       "   202                                                   #f-test\n",
       "   203         1          2.0      2.0      0.0          if (stdev_new*stdev_new)/(stdev_h*stdev_h) > phi_opt:\n",
       "   204                                                           return self.drift_reaction(\"f\")\n",
       "   205                                               \n",
       "   206                                                   #t-test\n",
       "   207         1          1.0      1.0      0.0          if avg_new-avg_h > self.rigor * stdev_h:\n",
       "   208                                                       return self.drift_reaction(\"t\")\n",
       "   209                                           \n",
       "   210                                                   \n",
       "   211         1          2.0      2.0      0.0          self.drift_detected_last_it = False\n",
       "   212         1          2.0      2.0      0.0          self._drift_detected = False\n",
       "   213         1          2.0      2.0      0.0          self.in_warning_zone = False\n",
       "   214         1          1.0      1.0      0.0          self.sequence_drifts = 0\n",
       "   215         1          2.0      2.0      0.0          self.sequence_no_drifts += 1\n",
       "   216         1          1.0      1.0      0.0          return self"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f opt.update opt.update(dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
