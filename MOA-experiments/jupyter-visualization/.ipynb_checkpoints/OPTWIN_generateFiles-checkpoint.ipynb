{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6efdc3c6-8c51-4e84-9afe-faf13c896f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, precision_score, recall_score, f1_score\n",
    "#import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import random\n",
    "import math\n",
    "import statistics\n",
    "import scipy.stats\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t as t_stat\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "from river.base import DriftDetector\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'The iteration is not making good progress')\n",
    "\n",
    "# Import the online learning metrics and algorithms from the River library\n",
    "from river import metrics\n",
    "from river import stream\n",
    "from river import tree,neighbors,naive_bayes,ensemble,linear_model\n",
    "from river import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef4e0b2c-f8a0-49be-aeb1-0956e7d4b4dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#OLD (WORKING)\n",
    "class Optwin_river(DriftDetector):\n",
    "    #pre-compute optimal cut for all possible window sizes\n",
    "    def pre_compute_cuts(self, opt_cut, opt_phi):\n",
    "        if len(opt_cut) != 0 and len(opt_phi) != 0:\n",
    "            return opt_cut, opt_phi\n",
    "        self.W = []\n",
    "        for i in range(self.w_lenght_max+1):\n",
    "            if i < self.w_lenght_min:\n",
    "                opt_cut[i] = 0\n",
    "                opt_phi[i] = 0\n",
    "            else:\n",
    "                optimal_cut = fsolve(self.t_test, (len(self.W)-29)/len(self.W))\n",
    "                optimal_cut = math.floor(optimal_cut[0]*len(self.W)) #parse to integer\n",
    "                optimal_cut = max(math.ceil(len(self.W)/2), optimal_cut) #### <- this is new!!!!!\n",
    "                #phi_opt = scipy.stats.f.ppf(q=self.confidence_two_tailes, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
    "                phi_opt = scipy.stats.f.ppf(q=self.confidence, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
    "                opt_cut[i] = optimal_cut\n",
    "                opt_phi[i] = phi_opt\n",
    "            self.W.append(1)\n",
    "        self.W = []\n",
    "        return opt_cut, opt_phi\n",
    "    \n",
    "    def detect_outlier(self, x):\n",
    "        #add outliers back to historical window (they will make it harder to detect drifts from outliers in the new window)\n",
    "        while len(self.outliers_positions) > 0 and self.itt - self.outliers_positions[0] > len(self.W) - self.last_opt_cut:\n",
    "            value = self.outliers.pop(0)\n",
    "            position = self.outliers_positions.pop(0)\n",
    "            substitute = self.outliers_substitutes.pop(0)\n",
    "            self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, [substitute]) #remove substitute\n",
    "            self.stdev_h, self.summation_h, self.count_h, self.S_h = self.add_running_stdev(self.summation_h, self.count_h, self.S_h, [value]) #put back smallest outlier\n",
    "            self.W[self.last_opt_cut-1] = value\n",
    "        \n",
    "        historical_avg = self.summation_h / self.count_h\n",
    "        \n",
    "        #check if x is not an outlier\n",
    "        if x <= historical_avg + (self.stdev_h * self.outlier_threshold) and x >= historical_avg - (self.stdev_h * self.outlier_threshold):\n",
    "            return x\n",
    "        \n",
    "        #add x as outlier\n",
    "        self.outliers.append(x)\n",
    "        self.outliers_positions.append(self.itt)\n",
    "        self.outliers_substitutes.append(historical_avg)\n",
    "        \n",
    "        #pop smallest outlier from new_window if max_outliers is reached\n",
    "        if len(self.outliers) > self.max_outliers:\n",
    "            #check min outlier and its respective index\n",
    "            min_outlier_value = min(self.outliers, key=lambda x:abs(x-historical_avg))\n",
    "            min_outlier_idx = self.outliers.index(min_outlier_value)\n",
    "            \n",
    "            #add min outlier back to new_window\n",
    "            self.outliers.pop(min_outlier_idx)\n",
    "            position = self.outliers_positions.pop(min_outlier_idx)\n",
    "            position_in_W = len(self.W) - (self.itt - position)\n",
    "            substitute = self.outliers_substitutes.pop(min_outlier_idx)\n",
    "            self.stdev_new, self.summation_new, self.count_new, self.S_new = self.pop_from_running_stdev(self.summation_new, self.count_new, self.S_new, [substitute]) #remove substitute\n",
    "            self.stdev_new, self.summation_new, self.count_new, self.S_new = self.add_running_stdev(self.summation_new, self.count_new, self.S_new, [min_outlier_value]) #put back smallest outlier \n",
    "            self.W[position_in_W-1] = min_outlier_value\n",
    "        return historical_avg\n",
    "\n",
    "    \n",
    "    def insert_to_W(self, x):\n",
    "        if self.outlier_detection and len(self.W) > self.w_lenght_min:\n",
    "            x = self.detect_outlier(x)\n",
    "            \n",
    "        self.W.append(x)\n",
    "        \n",
    "        #add new value to running stdev\n",
    "        if self.running_average:\n",
    "            self.stdev_new, self.summation_new, self.count_new, self.S_new = self.add_running_stdev(self.summation_new, self.count_new, self.S_new, [x])\n",
    "        \n",
    "        #check if window is too large\n",
    "        if len(self.W) > self.w_lenght_max:\n",
    "            pop = self.W.pop(0)\n",
    "            #remove excedent value from running stdev\n",
    "            if self.running_average:\n",
    "                self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, [pop])\n",
    "                #walk with sliding window\n",
    "                self.stdev_new, self.summation_new, self.count_new, self.S_new = self.pop_from_running_stdev(self.summation_new, self.count_new, self.S_new, [self.W[self.last_opt_cut]])\n",
    "                self.stdev_h, self.summation_h, self.count_h, self.S_h = self.add_running_stdev(self.summation_h, self.count_h, self.S_h, [self.W[self.last_opt_cut]])\n",
    "        \n",
    "        self.itt += 1\n",
    "        return\n",
    "    \n",
    "    #https://stats.stackexchange.com/questions/24878/computation-of-new-standard-deviation-using-old-standard-deviation-after-change\n",
    "    def add_running_stdev(self, summation, count, S, x):\n",
    "        x_sum = sum(x)\n",
    "        if count >= 1:\n",
    "            oldMean = summation / count\n",
    "            summation += x_sum\n",
    "            count += len(x)\n",
    "            newMean = summation / count\n",
    "            for i in x:\n",
    "                S = S + (i-oldMean)*(i-newMean)\n",
    "                #            S = S + (x_sum-oldMean)*(x_sum-newMean)\n",
    "        else:\n",
    "            summation = x_sum\n",
    "            count = len(x)\n",
    "            if count <= 1:\n",
    "                S = 0\n",
    "            else:\n",
    "                newMean = summation / count\n",
    "                S = pow(scipy.stats.tstd(x),2)*(count-1)\n",
    "        #estimated Variance = (S / (k-1) )\n",
    "        #estimated Standard Deviation = sqrt(variance)\n",
    "        if (count > 1 and S > 0):\n",
    "            return math.sqrt(S / (count-1) ), summation, count, S\n",
    "        else:\n",
    "            return 0, summation, count, S\n",
    "        \n",
    "    def pop_from_running_stdev(self,summation, count, S, x):\n",
    "        if count > len(x):\n",
    "            oldMean = summation / count\n",
    "            x_sum = sum(x)\n",
    "            summation -= x_sum\n",
    "            count -= len(x)\n",
    "            newMean = summation / count\n",
    "            for i in x:\n",
    "                S = S - ((i-oldMean)*(i-newMean))\n",
    "        else:\n",
    "            summation = 0\n",
    "            count = 0 \n",
    "            S = 0\n",
    "        #estimated Variance = (S / (k-1) )\n",
    "        #estimated Standard Deviation = sqrt(variance)\n",
    "        if (count > 1 and S > 0):\n",
    "            return math.sqrt(S / (count-1) ), summation, count, S\n",
    "        else:\n",
    "            return 0, summation, count, S\n",
    "    \n",
    "    #add new element to window\n",
    "    def update(self, x):\n",
    "        x += 1\n",
    "        #add new element to window\n",
    "        self.iteration += 1\n",
    "        self.insert_to_W(x)\n",
    "        #check if window is too small\n",
    "        if len(self.W) < self.w_lenght_min:\n",
    "            self.drift_detected_last_it = False\n",
    "            self._drift_detected = False\n",
    "            self.in_warning_zone = True\n",
    "            self.sequence_drifts = 0\n",
    "            return False\n",
    "        \n",
    "        #check optimal window cut and phi\n",
    "        if self.pre_compute_optimal_cut:\n",
    "            #get pre-calculated optimal window cut and phi\n",
    "            optimal_cut = self.opt_cut[len(self.W)]\n",
    "            phi_opt = self.opt_phi[len(self.W)]\n",
    "        else:\n",
    "            #calculate optimal window cut and phi in real-time\n",
    "            if len(self.W) in self.opt_cut:\n",
    "                optimal_cut = self.opt_cut[len(self.W)]\n",
    "                phi_opt = self.opt_phi[len(self.W)]\n",
    "            else:\n",
    "                optimal_cut = fsolve(self.t_test, (len(self.W)-30)/len(self.W))\n",
    "                optimal_cut = math.floor(optimal_cut[0]*len(self.W)) #parse to integer\n",
    "                #phi_opt = scipy.stats.f.ppf(q=self.confidence_two_tailes, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
    "                phi_opt = scipy.stats.f.ppf(q=self.confidence, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
    "                self.opt_cut[len(self.W)] = optimal_cut\n",
    "                self.opt_phi[len(self.W)] = phi_opt\n",
    "                \n",
    "        \n",
    "        #update stdev and avg\n",
    "        if self.running_average:\n",
    "            #update running stdev and avg\n",
    "            if optimal_cut > self.last_opt_cut: #remove elements from window_new and add them to window_h\n",
    "                self.stdev_new, self.summation_new, self.count_new, self.S_new = self.pop_from_running_stdev(self.summation_new, self.count_new, self.S_new, self.W[self.last_opt_cut:optimal_cut])\n",
    "                self.stdev_h, self.summation_h, self.count_h, self.S_h = self.add_running_stdev(self.summation_h, self.count_h, self.S_h, self.W[self.last_opt_cut:optimal_cut])\n",
    "            elif optimal_cut < self.last_opt_cut: #remove elements from window_h and add them to window_new\n",
    "                self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, self.W[optimal_cut:self.last_opt_cut])\n",
    "                self.stdev_new, self.summation_new, self.count_new, self.S_new = self.add_running_stdev(self.summation_new, self.count_new, self.S_new, self.W[optimal_cut:self.last_opt_cut])\n",
    "            avg_h = self.summation_h / self.count_h\n",
    "            avg_new = self.summation_new / self.count_new\n",
    "            stdev_h = self.stdev_h\n",
    "            stdev_new = self.stdev_new\n",
    "            self.last_opt_cut = optimal_cut\n",
    "        else:\n",
    "            #recalculate stdev and avg\n",
    "            stdev_h = scipy.stats.tstd(self.W[:optimal_cut])\n",
    "            stdev_new = scipy.stats.tstd(self.W[optimal_cut:])\n",
    "            avg_h = sum(self.W[:optimal_cut]) / optimal_cut\n",
    "            avg_new = sum(self.W[optimal_cut:]) / (len(self.W[optimal_cut:]))\n",
    "            self.last_opt_cut = optimal_cut\n",
    "        \n",
    "        #add minimal noise to stdev\n",
    "        if stdev_h == 0 or stdev_new == 0:\n",
    "            stdev_h += self.minimum_noise\n",
    "            stdev_new += self.minimum_noise\n",
    "        \n",
    "        #check both sides of f and t-test (detexts drift and model that is still convergeding)\n",
    "        '''    \n",
    "        #f-test     \n",
    "        if max((stdev_new*stdev_new)/(stdev_h*stdev_h),(stdev_h*stdev_h)/(stdev_new*stdev_new)) > phi_opt:\n",
    "                return self.drift_reaction(\"f\")\n",
    "    \n",
    "        #t-test\n",
    "        if max(avg_h-avg_new,avg_new-avg_h) > self.rigor * stdev_h:\n",
    "            return self.drift_reaction(\"t\")\n",
    "\n",
    "        '''\n",
    "        \n",
    "        #check only one side of f and t-test (if the loss decreases it means that the model is learning, not that a concept drift occurred\n",
    "        #f-test     \n",
    "        if (stdev_new*stdev_new)/(stdev_h*stdev_h) > phi_opt:\n",
    "                return self.drift_reaction(\"f\")\n",
    "    \n",
    "        #t-test\n",
    "        if avg_new-avg_h > self.rigor * stdev_h:\n",
    "            return self.drift_reaction(\"t\")\n",
    "\n",
    "        \n",
    "        self.drift_detected_last_it = False\n",
    "        self._drift_detected = False\n",
    "        self.in_warning_zone = False\n",
    "        self.sequence_drifts = 0\n",
    "        self.sequence_no_drifts += 1\n",
    "        return self\n",
    "    \n",
    "    def drift_reaction(self, drift_type):\n",
    "        #print(self.itt)\n",
    "        self.sequence_drifts += 1\n",
    "        self.sequence_no_drifts = 0\n",
    "        #if self.sequence_drifts < 1:\n",
    "        #    return False\n",
    "            \n",
    "        self.drift_type.append(drift_type)\n",
    "        self.drifts.append(self.iteration)\n",
    "        if self.fixed_window_size == -1:\n",
    "            if self.empty_w:\n",
    "                self.empty_window()\n",
    "            else:\n",
    "                if self.running_average:\n",
    "                    self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, self.W[:optimal_cut])\n",
    "                self.W = self.W[optimal_cut:]\n",
    "                \n",
    "        self.drift_detected_last_it = True\n",
    "        self.in_warning_zone = True\n",
    "        self._drift_detected = True\n",
    "        self.outliers = []\n",
    "        self.outliers_substitutes = []\n",
    "        self.outliers_positions = []\n",
    "        return True\n",
    "        \n",
    "    def reset(self):\n",
    "        self.empty_window()\n",
    "        self.drifts = []\n",
    "        self.drift_type = []\n",
    "        self.itt = 0\n",
    "        self._reset()\n",
    "    \n",
    "    def empty_window(self):\n",
    "        self.W = []\n",
    "        self.sequence_drifts = 0\n",
    "        if self.running_average:\n",
    "            self.stdev_new = 0\n",
    "            self.summation_new = 0\n",
    "            self.count_new = 0\n",
    "            self.S_new = 0\n",
    "            self.stdev_h = 0\n",
    "            self.summation_h = 0\n",
    "            self.count_h = 0\n",
    "            self.S_h = 0\n",
    "            self.last_opt_cut = 0\n",
    "        self.outliers = []\n",
    "        self.outliers_substitutes = []\n",
    "        self.outliers_positions = []\n",
    "            \n",
    "    def detected_change(self):\n",
    "        return self.drift_detected_last_it\n",
    "    \n",
    "    def get_length_estimation(self):\n",
    "        self.estimation = len(self.W)\n",
    "        return len(self.W)\n",
    "    \n",
    "    def detected_warning_zone(self):\n",
    "        if self.sequence_drifts > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __init__(self, confidence_final = 0.999, rigor = 0.3, fixed_window_size = -1, empty_w=True, w_lenght_max = 10000, w_lenght_min = 60, minimum_noise = 1e-15, opt_cut = {}, opt_phi = {}, max_outliers = 5, outlier_threshold = 3, pre_compute_optimal_cut = True, running_average = True, outlier_detection= True):\n",
    "        #init variables\n",
    "        super().__init__()\n",
    "        self.confidence_final = confidence_final #confidence value chosen by user\n",
    "        self.rigor = rigor #rigorousness of drift identification\n",
    "        self.w_lenght_max = w_lenght_max #maximum window size\n",
    "        self.w_lenght_min = w_lenght_min #minimum window size\n",
    "        self.minimum_noise = minimum_noise #noise to be added to stdev in case it is 0\n",
    "        self.fixed_window_size = fixed_window_size #minimum window size\n",
    "        self.pre_compute_optimal_cut = pre_compute_optimal_cut #pre_compute all possible window sizes?\n",
    "        self.running_average = running_average #calculate stdev and avg with running sliding window?\n",
    "        self.empty_w = empty_w #empty window when drift is detected\n",
    "        \n",
    "        \n",
    "        self.W = [] #window\n",
    "        self.opt_cut = opt_cut #pre-calculated optimal cut for all possible windows\n",
    "        self.opt_phi = opt_phi #pre-calculated optimal phi for all possible windows\n",
    "        self.last_opt_cut = 0\n",
    "        self.drifts = [] #drifts identified \n",
    "        self.drift_type = [] #types of drifts identified\n",
    "        self.iteration = 0 #current iteration step\n",
    "        self.confidence = pow(self.confidence_final, 1/2) #confidence used on the t-test\n",
    "        #self.confidence_two_tailes = 1-(1-self.confidence)/2 #confidence used on the f-test\n",
    "        self.t_score = lambda w_lenght : t_stat.ppf(self.confidence, df=w_lenght-2) #t_value to achieve desired confidence\n",
    "        #self.f_test = lambda n : scipy.stats.f.ppf(q=self.confidence_two_tailes, dfn=(n*len(self.W))-1, dfd=len(self.W)-(n*len(self.W))-1) #f-test formula\n",
    "        self.f_test = lambda n : scipy.stats.f.ppf(q=self.confidence, dfn=(n*len(self.W))-1, dfd=len(self.W)-(n*len(self.W))-1) #f-test formula\n",
    "        self.t_test = lambda n : self.rigor - (self.t_score(len(self.W)) * np.sqrt((1/(len(self.W)*n))+((1* self.f_test(n))/((1-n)*len(self.W))))) #t-test formula (stdev_h=1 because it is cancelled during solution)\n",
    "    \n",
    "        #Running stdev and avg\n",
    "        self.stdev_new = 0\n",
    "        self.summation_new = 0\n",
    "        self.count_new = 0\n",
    "        self.S_new = 0\n",
    "        self.stdev_h = 0\n",
    "        self.summation_h = 0\n",
    "        self.count_h = 0\n",
    "        self.S_h = 0\n",
    "        \n",
    "        #Current outliers\n",
    "        self.max_outliers = max_outliers\n",
    "        self.biggest_non_outlier = 0\n",
    "        self.outliers = []\n",
    "        self.outliers_substitutes = []\n",
    "        self.outliers_positions = []\n",
    "        self.outlier_threshold = outlier_threshold\n",
    "        self.outlier_detection = outlier_detection\n",
    "        \n",
    "        self.itt = 0\n",
    "    \n",
    "        self.drift_detected_last_it = False\n",
    "        self.in_concept_change = False\n",
    "        self.in_warning_zone = False\n",
    "        self.estimation = 0.0\n",
    "        self.delay = 0.0\n",
    "        self.sequence_drifts = 0\n",
    "        self.sequence_no_drifts = 0\n",
    "        \n",
    "    \n",
    "        if self.fixed_window_size != -1:\n",
    "            self.w_lenght_max = self.fixed_window_size\n",
    "            self.w_lenght_min = self.fixed_window_size   \n",
    "            self.pre_compute_optimal_cut = False\n",
    "    \n",
    "        #pre-compute optimal cut for all possible window sizes (if True)\n",
    "        if self.pre_compute_optimal_cut:\n",
    "            self.opt_cut, self.opt_phi = self.pre_compute_cuts(self.opt_cut, self.opt_phi)\n",
    "            \n",
    "        if len(self.opt_cut) >= w_lenght_max and len(self.opt_phi) >= w_lenght_max:\n",
    "            self.pre_compute_optimal_cut = True\n",
    "\n",
    "        #super().reset()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9c10c7a-b708-4b04-9160-584c79db3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New\n",
    "class Optwin_river(DriftDetector):\n",
    "    #pre-compute optimal cut for all possible window sizes\n",
    "    def pre_compute_cuts(self, opt_cut, opt_phi, t_stats, t_stats_warning):\n",
    "        if len(opt_cut) != 0 and len(opt_phi) != 0 and len(t_stats) != 0 and len(t_stats_warning) != 0:\n",
    "            return opt_cut, opt_phi, t_stats, t_stats_warning\n",
    "        self.W = []\n",
    "        for i in range(self.w_lenght_max+1):\n",
    "            if i < self.w_lenght_min:\n",
    "                opt_cut.append(0)\n",
    "                opt_phi.append(0)\n",
    "                t_stats.append(0.0)\n",
    "                t_stats_warning.append(0.0)\n",
    "            else:\n",
    "                optimal_cut = fsolve(self.t_test, (len(self.W)-self.w_lenght_min)/len(self.W))\n",
    "                #check if opt_cut was found\n",
    "                tolerance = 1e-6\n",
    "                if abs(self.t_test(optimal_cut[0])) <= tolerance:\n",
    "                    optimal_cut = math.floor(optimal_cut[0]*len(self.W)) #parse to integer\n",
    "                else: #opt_cut not found\n",
    "                    optimal_cut = math.floor((len(self.W)/2)+1)\n",
    "                \n",
    "                ##test!\n",
    "                #if optimal_cut < opt_cut[-1]:\n",
    "                #    optimal_cut = opt_cut[-1]\n",
    "                \n",
    "                \n",
    "                #phi_opt = scipy.stats.f.ppf(q=self.confidence_two_tailes, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
    "                phi_opt = scipy.stats.f.ppf(q=self.confidence, dfn=optimal_cut-1, dfd=len(self.W)-optimal_cut-1) \n",
    "                opt_cut.append(optimal_cut)\n",
    "                opt_phi.append(phi_opt)\n",
    "                t_stats.append(self.t_score(optimal_cut/i))\n",
    "                t_stats_warning.append(self.t_score_warning(optimal_cut/i))\n",
    "            self.W.append(1)\n",
    "        self.W = []\n",
    "        \n",
    "        return opt_cut, opt_phi, t_stats, t_stats_warning\n",
    "    \n",
    "    def insert_to_W(self, x):\n",
    "        self.W.append(x)\n",
    "        \n",
    "        #add new value to running stdev\n",
    "        self.stdev_new, self.summation_new, self.count_new, self.S_new = self.add_running_stdev(self.summation_new, self.count_new, self.S_new, [x])\n",
    "        \n",
    "        #check if window is too large\n",
    "        if len(self.W) > self.w_lenght_max:\n",
    "            pop = self.W.pop(0)\n",
    "            #pop = self.W.popleft()\n",
    "            \n",
    "            #remove excedent value from running stdev\n",
    "            self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, [pop])\n",
    "            #walk with sliding window\n",
    "            self.stdev_new, self.summation_new, self.count_new, self.S_new = self.pop_from_running_stdev(self.summation_new, self.count_new, self.S_new, [self.W[self.last_opt_cut]])\n",
    "            self.stdev_h, self.summation_h, self.count_h, self.S_h = self.add_running_stdev(self.summation_h, self.count_h, self.S_h, [self.W[self.last_opt_cut]])\n",
    "            \n",
    "        self.itt += 1\n",
    "        return\n",
    "    \n",
    "    #https://stats.stackexchange.com/questions/24878/computation-of-new-standard-deviation-using-old-standard-deviation-after-change\n",
    "    def add_running_stdev(self, summation, count, S, x):\n",
    "        summation += sum(x)\n",
    "        count += len(x)\n",
    "        S += sum([i*i for i in x])\n",
    "                \n",
    "        if (count > 1 and S > 0):\n",
    "            stdev = math.sqrt((count*S) - (summation*summation)) / count\n",
    "            return stdev, summation, count, S\n",
    "        else:\n",
    "            return 0, summation, count, S\n",
    "        \n",
    "    def pop_from_running_stdev(self,summation, count, S, x):\n",
    "        summation -= sum(x)\n",
    "        count -= len(x)\n",
    "        S -= sum([i*i for i in x])\n",
    "        \n",
    "        if (count > 1 and S > 0):\n",
    "            stdev = math.sqrt((count*S) - (summation*summation)) / count\n",
    "            return stdev, summation, count, S\n",
    "        else:\n",
    "            return 0, summation, count, S \n",
    "    \n",
    "    #add new element to window\n",
    "    def update(self, x):\n",
    "        #add new element to window\n",
    "        self.iteration += 1\n",
    "        self.insert_to_W(x)\n",
    "        self.delay = 0\n",
    "        \n",
    "        #check if window is too small\n",
    "        if len(self.W) < self.w_lenght_min:\n",
    "            self._drift_detected = False\n",
    "            self.in_warning_zone = False\n",
    "            return False\n",
    "        \n",
    "        #check optimal window cut and phi\n",
    "        #get pre-calculated optimal window cut and phi\n",
    "        optimal_cut = self.opt_cut[len(self.W)]\n",
    "        phi_opt = self.opt_phi[len(self.W)]\n",
    "                     \n",
    "        #update running stdev and avg\n",
    "        if optimal_cut > self.last_opt_cut: #remove elements from window_new and add them to window_h\n",
    "            self.stdev_new, self.summation_new, self.count_new, self.S_new = self.pop_from_running_stdev(self.summation_new, self.count_new, self.S_new, self.W[self.last_opt_cut:optimal_cut])\n",
    "            self.stdev_h, self.summation_h, self.count_h, self.S_h = self.add_running_stdev(self.summation_h, self.count_h, self.S_h, self.W[self.last_opt_cut:optimal_cut])\n",
    "            #using deque\n",
    "            #self.stdev_new, self.summation_new, self.count_new, self.S_new = self.pop_from_running_stdev(self.summation_new, self.count_new, self.S_new, list(islice(self.W,self.last_opt_cut,optimal_cut)))\n",
    "            #self.stdev_h, self.summation_h, self.count_h, self.S_h = self.add_running_stdev(self.summation_h, self.count_h, self.S_h, list(islice(self.W,self.last_opt_cut,optimal_cut)))\n",
    "        elif optimal_cut < self.last_opt_cut: #remove elements from window_h and add them to window_new\n",
    "            self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, self.W[optimal_cut:self.last_opt_cut])\n",
    "            self.stdev_new, self.summation_new, self.count_new, self.S_new = self.add_running_stdev(self.summation_new, self.count_new, self.S_new, self.W[optimal_cut:self.last_opt_cut])\n",
    "            #using deque\n",
    "            #self.stdev_h, self.summation_h, self.count_h, self.S_h = self.pop_from_running_stdev(self.summation_h, self.count_h, self.S_h, list(islice(self.W,optimal_cut,self.last_opt_cut)))\n",
    "            #self.stdev_new, self.summation_new, self.count_new, self.S_new = self.add_running_stdev(self.summation_new, self.count_new, self.S_new, list(islice(self.W,optimal_cut,self.last_opt_cut)))\n",
    "\n",
    "        avg_h = self.summation_h / self.count_h\n",
    "        avg_new = self.summation_new / self.count_new\n",
    "        #stdev_h = self.stdev_h\n",
    "        #stdev_new = self.stdev_new\n",
    "        stdev_h = math.sqrt((self.count_h*self.S_h) - (self.summation_h*self.summation_h)) / self.count_h\n",
    "        stdev_new = math.sqrt((self.count_new*self.S_new) - (self.summation_new*self.summation_new)) / self.count_new\n",
    "        \n",
    "        self.last_opt_cut = optimal_cut\n",
    "\n",
    "        \n",
    "        #add minimal noise to stdev\n",
    "        stdev_h += self.minimum_noise\n",
    "        stdev_new += self.minimum_noise\n",
    "        \n",
    "        #check only one side of f and t-test (if the loss decreases it means that the model is learning, not that a concept drift occurred\n",
    "        #f-test\n",
    "        \n",
    "        if (stdev_new*stdev_new/(stdev_h*stdev_h)) > phi_opt:\n",
    "            self.drift_reaction(\"f\")\n",
    "            return True\n",
    "        \n",
    "        '''if avg_h - avg_new < 0:\n",
    "                self.drift_reaction(\"f\")\n",
    "                #self.insert_to_W(x)\n",
    "                return True\n",
    "            else:\n",
    "                self.empty_window()\n",
    "                self.insert_to_W(x)\n",
    "                self._drift_detected = False\n",
    "                self.in_warning_zone = False\n",
    "                return False'''\n",
    "        \n",
    "        #check t-stat\n",
    "        if self.pre_compute_optimal_cut:\n",
    "            t_stat = self.t_stats[len(self.W)]\n",
    "            t_stat_warning = self.t_stats_warning[len(self.W)]\n",
    "        else:\n",
    "            t_stat = self.t_score(optimal_cut/self.W.lenght)\n",
    "            t_stat_warning = self.t_score_warning(optimal_cut/self.W.lenght)\n",
    "                \n",
    "        #t-test\n",
    "        t_test_result = (avg_new-avg_h) / (math.sqrt((stdev_new/(len(self.W)-optimal_cut))+(stdev_h/optimal_cut)))\n",
    "        if  t_test_result > t_stat:\n",
    "            self.drift_reaction(\"t\")\n",
    "            #self.insert_to_W(x)\n",
    "            return True\n",
    "        elif t_test_result > t_stat_warning:\n",
    "            self.in_warning_zone = True\n",
    "            return False\n",
    "        \n",
    "        self._drift_detected = False\n",
    "        self.in_warning_zone = False\n",
    "        return False\n",
    "    \n",
    "    def drift_reaction(self, drift_type):            \n",
    "        self.drift_type.append(drift_type)\n",
    "        self.drifts.append(self.iteration)                \n",
    "        self.drift_detected_last_it = True\n",
    "        self._drift_detected = True\n",
    "        self.empty_window()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    def reset(self):\n",
    "        self.empty_window()\n",
    "        self.drift_detected_last_it = False\n",
    "        self._drift_detected = False\n",
    "        self._reset()\n",
    "    \n",
    "    def empty_window(self):\n",
    "        self.W = []\n",
    "        self.stdev_new = 0\n",
    "        self.summation_new = 0\n",
    "        self.count_new = 0\n",
    "        self.S_new = 0\n",
    "        self.stdev_h = 0\n",
    "        self.summation_h = 0\n",
    "        self.count_h = 0\n",
    "        self.S_h = 0\n",
    "        self.last_opt_cut = 0\n",
    "            \n",
    "    def detected_change(self):\n",
    "        return self.drift_detected_last_it\n",
    "    \n",
    "    def get_length_estimation(self):\n",
    "        self.estimation = len(self.W)\n",
    "        return len(self.W)\n",
    "    \n",
    "    def detected_warning_zone(self):\n",
    "        return self.in_warning_zone\n",
    "    \n",
    "    def __init__(self, confidence_final = 0.999, rigor = 0.5, empty_w=True, w_lenght_max = 50000, w_lenght_min = 30, minimum_noise = 1e-6, opt_cut = [], opt_phi = [], t_stats = [], t_stats_warning = []):\n",
    "        #init variables\n",
    "        super().__init__()\n",
    "        self.confidence_final = confidence_final #confidence value chosen by user\n",
    "        self.rigor = rigor #rigorousness of drift identification\n",
    "        self.w_lenght_max = w_lenght_max #maximum window size\n",
    "        self.w_lenght_min = w_lenght_min #minimum window size\n",
    "        self.minimum_noise = minimum_noise #noise to be added to stdev in case it is 0\n",
    "        self.pre_compute_optimal_cut = True #pre_compute all possible window sizes?\n",
    "        self.empty_w = empty_w #empty window when drift is detected\n",
    "        \n",
    "        self.W = [] #window\n",
    "        #self.W = deque()\n",
    "        self.opt_cut = opt_cut #pre-calculated optimal cut for all possible windows\n",
    "        self.opt_phi = opt_phi #pre-calculated optimal phi for all possible windows\n",
    "        self.t_stats = t_stats\n",
    "        self.t_stats_warning = t_stats_warning\n",
    "        self.last_opt_cut = 0\n",
    "        self.drifts = [] #drifts identified \n",
    "        self.drift_type = [] #types of drifts identified\n",
    "        self.iteration = 0 #current iteration step\n",
    "        self.confidence = pow(self.confidence_final, 1/4) #confidence used on the t-test\n",
    "        self.confidence_warning = 0.98\n",
    "        #self.confidence_two_tailes = 1-(1-self.confidence)/2 #confidence used on the f-test\n",
    "        self.t_score = lambda n : t_stat.ppf(self.confidence, df=self.degree_freedom(n)) #t_value to achieve desired confidence\n",
    "        self.t_score_warning = lambda n : t_stat.ppf(self.confidence_warning, df=self.degree_freedom(n)) #t_value to achieve desired confidence\n",
    "        self.f_test = lambda n : scipy.stats.f.ppf(q=self.confidence, dfn=(n*len(self.W))-1, dfd=len(self.W)-(n*len(self.W))-1) #f-test formula\n",
    "        self.degree_freedom = lambda n : pow(((1/max(len(self.W)*n,1e-15))+((1/pow(self.f_test(n),2))/((1-n)*len(self.W)))),2)/((1/max((pow((len(self.W)*n),2)*((len(self.W)*n)-1)),1e-15))+(pow((1/pow(self.f_test(n),2)),2)/max((pow(((1-n)*len(self.W)),2)*(((1-n)*len(self.W))-1)),1e-15)))\n",
    "        self.t_test = lambda n : self.rigor - (self.t_score(n) * np.sqrt((1/(len(self.W)*n))+((1* self.f_test(n))/((1-n)*len(self.W))))) #t-test formula (stdev_h=1 because it is cancelled during solution)\n",
    "\n",
    "        \n",
    "        #Running stdev and avg\n",
    "        self.stdev_new = 0\n",
    "        self.summation_new = 0\n",
    "        self.count_new = 0\n",
    "        self.S_new = 0\n",
    "        self.stdev_h = 0\n",
    "        self.summation_h = 0\n",
    "        self.count_h = 0\n",
    "        self.S_h = 0\n",
    "        \n",
    "        self.itt = 0\n",
    "    \n",
    "        self.drift_detected_last_it = False\n",
    "        self.in_concept_change = False\n",
    "        self.in_warning_zone = False\n",
    "        self.estimation = 0.0\n",
    "        self.delay = 0.0\n",
    "        self.sequence_drifts = 0\n",
    "        self.sequence_no_drifts = 0\n",
    "    \n",
    "        #pre-compute optimal cut for all possible window sizes (if True)\n",
    "        if self.pre_compute_optimal_cut:\n",
    "            self.opt_cut, self.opt_phi, self.t_stats, self.t_stats_warning = self.pre_compute_cuts(self.opt_cut, self.opt_phi, self.t_stats, self.t_stats_warning)\n",
    "            \n",
    "        if len(self.opt_cut) == 0:\n",
    "            self.opt_cut = [0 for i in range(w_lenght_min)]\n",
    "            self.opt_phi = [0 for i in range(w_lenght_min)]\n",
    "            self.t_stats = [0.0 for i in range(w_lenght_min)]\n",
    "            self.t_stats_warning = [0.0 for i in range(w_lenght_min)]\n",
    "            \n",
    "        if len(self.opt_cut) >= w_lenght_max and len(self.opt_phi) >= w_lenght_max:\n",
    "            self.pre_compute_optimal_cut = True\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2b255-d542-4eeb-ab3f-1219e35250fa",
   "metadata": {},
   "source": [
    "## Save cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8254e0a7-cedf-4103-81ee-5299f88f709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cuts(rigor = 0.05, error = 1e-3, w_lenght_min=30, max_samples = 50000):\n",
    "    confidence_final = 1-error\n",
    "\n",
    "    opt2 = Optwin_river(w_lenght_max=max_samples+1, w_lenght_min=w_lenght_min, rigor = rigor, confidence_final=confidence_final)\n",
    "    opt_cut = []\n",
    "    opt_phi = []\n",
    "    t_stats = []\n",
    "    t_stats_warning= []\n",
    "    opt_cut, opt_phi, t_stats, t_stats_warning = opt2.pre_compute_cuts(opt_cut, opt_phi, t_stats, t_stats_warning)\n",
    "    opt = Optwin_river(w_lenght_max=max_samples+1, w_lenght_min=w_lenght_min, rigor = rigor, confidence_final=confidence_final, opt_cut=opt_cut, opt_phi=opt_phi, t_stats=t_stats, t_stats_warning=t_stats_warning)\n",
    "    \n",
    "    '''\n",
    "    f = open(\"/Users/mauro.dalleluccatosi/Documents/Jupyter_notebooks/data/opt_cut_updated_\"+str(w_lenght_min)+\"-\"+str(max_samples)+\"_\"+str(error)+\"_\"+str(rigor)+\"r.csv\", \"w\")\n",
    "    f.write(str(confidence_final)+\",\"+str(rigor)+\",\"+ str(max_samples) + \",\" +str(w_lenght_min))\n",
    "    for i in opt_cut:\n",
    "        f.write(\",\"+str(i))\n",
    "\n",
    "    for i in opt_phi:\n",
    "        f.write(\",\"+str(i))\n",
    "    \n",
    "    for i in t_stats:\n",
    "        f.write(\",\"+str(i))\n",
    "    \n",
    "    for i in t_stats_warning:\n",
    "        f.write(\",\"+str(i))\n",
    "    \n",
    "    f.close()  \n",
    "    '''\n",
    "    return {'rigor': rigor, 'error': error, 'max_samples':max_samples, 'opt_cut':opt_cut, 'opt_phi': opt_phi, 't_stats': t_stats, 't_stats_warning': t_stats_warning}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa20b046-4b8c-46d2-8aa3-cf6d90949199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/q6cp8p7n06z0_2l_1b_m6sh4_pwsks/T/ipykernel_89560/1102990811.py:233: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.t_test = lambda n : self.rigor - (self.t_score(n) * np.sqrt((1/(len(self.W)*n))+((1* self.f_test(n))/((1-n)*len(self.W))))) #t-test formula (stdev_h=1 because it is cancelled during solution)\n",
      "/var/folders/2n/q6cp8p7n06z0_2l_1b_m6sh4_pwsks/T/ipykernel_89560/1102990811.py:233: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  self.t_test = lambda n : self.rigor - (self.t_score(n) * np.sqrt((1/(len(self.W)*n))+((1* self.f_test(n))/((1-n)*len(self.W))))) #t-test formula (stdev_h=1 because it is cancelled during solution)\n",
      "/var/folders/2n/q6cp8p7n06z0_2l_1b_m6sh4_pwsks/T/ipykernel_89560/1102990811.py:232: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.degree_freedom = lambda n : pow(((1/max(len(self.W)*n,1e-15))+((1/pow(self.f_test(n),2))/((1-n)*len(self.W)))),2)/((1/max((pow((len(self.W)*n),2)*((len(self.W)*n)-1)),1e-15))+(pow((1/pow(self.f_test(n),2)),2)/max((pow(((1-n)*len(self.W)),2)*(((1-n)*len(self.W))-1)),1e-15)))\n",
      "/var/folders/2n/q6cp8p7n06z0_2l_1b_m6sh4_pwsks/T/ipykernel_89560/1102990811.py:232: RuntimeWarning: invalid value encountered in divide\n",
      "  self.degree_freedom = lambda n : pow(((1/max(len(self.W)*n,1e-15))+((1/pow(self.f_test(n),2))/((1-n)*len(self.W)))),2)/((1/max((pow((len(self.W)*n),2)*((len(self.W)*n)-1)),1e-15))+(pow((1/pow(self.f_test(n),2)),2)/max((pow(((1-n)*len(self.W)),2)*(((1-n)*len(self.W))-1)),1e-15)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 completed\n",
      "0.1 completed\n",
      "1.0 completed\n"
     ]
    }
   ],
   "source": [
    "max_samples=25000\n",
    "w_lenght_min=30\n",
    "rigors = [0.5, 0.1, 1.0]\n",
    "error = 0.01\n",
    "cuts = []\n",
    "for r in rigors:\n",
    "    cuts.append(save_cuts(rigor=r, max_samples=max_samples,w_lenght_min=w_lenght_min, error=error))\n",
    "    print(r, \"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fada5835-24f8-465a-aa91-b3f4713bdd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874916566546522"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "summation = 0\n",
    "for i in range(30, max_samples):\n",
    "    count += 1\n",
    "    summation += cuts[0]['opt_cut'][i]-cuts[0]['opt_cut'][i-1]\n",
    "    summation += cuts[1]['opt_cut'][i]-cuts[1]['opt_cut'][i-1]\n",
    "    summation += cuts[2]['opt_cut'][i]-cuts[2]['opt_cut'][i-1]\n",
    "    \n",
    "total = summation / (3*count)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eeb2ced-f953-4520-9768-b7b01d190a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuts[0]['opt_cut'][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c632f-05ca-4f9f-9788-8dde0d1bd5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef2d88-d2ae-46c6-b3b7-ce606e338450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5a7c3-335f-4241-9277-d1d2ccec14dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2dbc93-398e-418f-9494-6a8b60a266e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7ba15789-f4a2-49f4-b65c-b39ce6fdf3bf",
   "metadata": {},
   "source": [
    "## Save warning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c2ec97e-e88e-4bf4-b56d-878895783e85",
   "metadata": {},
   "source": [
    "warning_confidence = 0.98\n",
    "t_score_warning = lambda w_lenght : t_stat.ppf(warning_confidence, df=w_lenght-2) #t_value to achieve desired confidence\n",
    "\n",
    "f = open(\"/Users/mauro.dalleluccatosi/Documents/Jupyter_notebooks/data/opt_warning_confidence-\"+str(warning_confidence)+\".csv\", \"w\")\n",
    "f.write(str(warning_confidence))\n",
    "for i in range(max_samples+2):\n",
    "    if i < w_lenght_min:\n",
    "        f.write(\",\"+str(0.0))\n",
    "    else:\n",
    "        f.write(\",\"+str(t_score_warning(i)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d0704-9f18-4c92-82c2-5b6e1ccc3f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2459c846-c45c-4f6e-88c5-09212d5e3082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219a1289-62db-4847-8ace-28e09d62682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/q6cp8p7n06z0_2l_1b_m6sh4_pwsks/T/ipykernel_3647/3431259048.py:236: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.t_test = lambda n : self.rigor - (self.t_score(len(self.W)) * np.sqrt((1/(len(self.W)*n))+((1* self.f_test(n))/((1-n)*len(self.W))))) #t-test formula (stdev_h=1 because it is cancelled during solution)\n",
      "/var/folders/2n/q6cp8p7n06z0_2l_1b_m6sh4_pwsks/T/ipykernel_3647/3431259048.py:236: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.t_test = lambda n : self.rigor - (self.t_score(len(self.W)) * np.sqrt((1/(len(self.W)*n))+((1* self.f_test(n))/((1-n)*len(self.W))))) #t-test formula (stdev_h=1 because it is cancelled during solution)\n"
     ]
    }
   ],
   "source": [
    "# define parameters\n",
    "#max_samples = len(X_train) + len(X_test) #max size of the dataset\n",
    "max_samples = 25000 #max size of the dataset\n",
    "w_lenght_min=30 # > 30\n",
    "rigor = 0.05\n",
    "error = 1e-3\n",
    "confidence_final = 1-error\n",
    "\n",
    "confidence = pow(confidence_final, 1/2) #confidence used on the t-test\n",
    "t_score = lambda w_lenght : t_stat.ppf(confidence, df=w_lenght-2) #t_value to achieve desired confidence\n",
    "\n",
    "opt2 = Optwin_river(w_lenght_max=max_samples+1, w_lenght_min=w_lenght_min, rigor = rigor, confidence_final=confidence_final)\n",
    "opt_cut = []\n",
    "opt_phi = []\n",
    "t_stats = []\n",
    "t_stats_warning= []\n",
    "opt_cut, opt_phi, t_stats, t_stats_warning = opt2.pre_compute_cuts(opt_cut, opt_phi, t_stats, t_stats_warning)\n",
    "opt = Optwin_river(w_lenght_max=max_samples+1, w_lenght_min=w_lenght_min, rigor = rigor, confidence_final=confidence_final, opt_cut=opt_cut, opt_phi=opt_phi, t_stats=t_stats, t_stats_warning=t_stats_warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1d64abf-a11e-4f8e-9f82-73aa6e02e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/Users/mauro.dalleluccatosi/Documents/Jupyter_notebooks/data/opt_cut_half_\"+str(w_lenght_min)+\"-\"+str(max_samples)+\"_\"+str(error)+\"_\"+str(rigor)+\"r.csv\", \"w\")\n",
    "f.write(str(confidence_final)+\",\"+str(rigor)+\",\"+ str(max_samples) + \",\" +str(w_lenght_min))\n",
    "for i in opt_cut:\n",
    "    f.write(\",\"+str(i))\n",
    "    \n",
    "for i in opt_phi:\n",
    "    f.write(\",\"+str(i))\n",
    "    \n",
    "for i in range(len(opt_phi)):\n",
    "    if i < w_lenght_min:\n",
    "        f.write(\",\"+str(0.0))\n",
    "    else:\n",
    "        f.write(\",\"+str(t_score(i)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a010431-22ed-481a-b50b-d72191fd4b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd2bea-60b1-4525-a8c5-98b91d8f2686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
